## MySQL中有哪些存储引擎？

1. **InnoDB存储引擎**

InnoDB是MySQL的默认事务型引擎，也是最重要、使用最广泛的存储引擎。它被设计用来处理大量的短期(short-lived)事务，应该优先考虑InnoDB引擎。

2. **MylSAM存储引擎**

在MySQL 5.1及之前的版本，MyISAM是默认的存储引擎。MyISAM提供了大量的特性，包括全文索引、压缩、空间函数（GIS）等，但**MyISAM不支持事务和行级锁**，而且崩溃后无法安全恢复。MyISAM对整张表加锁，很容易因为表锁的问题导致典型的的性能问题。

3. **Mrg_MylSAM**

Merge存储引擎，是一组MyIsam的组合，也就是说，他将MyIsam引擎的多个表聚合起来，但是他的内部没有数据，真正的数据依然是MyIsam引擎的表中，但是可以直接进行查询、删除更新等操作。

4. **Archive引擎**

Archive存储引擎**只支持INSERT和SELECT操作**，会缓存所有的写并利用zlib对插入的行进行压缩，所以比MyISAM表的磁盘I/O更少。但是每次SELECT查询都需要执行全表扫描。所以Archive表适合日志和数据采集类应用，Archive引擎是一个针对高速插入和压缩做了优化的简单引擎。

5. **Blackhole引擎**

Blackhole引擎没有实现任何的存储机制，它会丢弃所有插入的数据，不做任何保存。可以在一些特殊的复制架构和日志审核时发挥作用。但这种引擎在应用方式上有很多问题，因此并不推荐。

6. **CSV引擎**

CSV引擎可以将普通的CSV文件(逗号分割值的文件）作为MySQL的表来处理，但这种表不支持索引。因此CSV引擎可以作为一种数据交换的机制，非常有用。

7. **Federated引擎**

Federated引擎是**访问其他MySQL服务器的一个代理**，它会创建一个到远程MySQL服务器的客户端连接，并将查询传输到远程服务器执行，然后提取或者发送需要的数据。默认是禁用的。

8. **Memory 引擎**

Memory表至少比MyISAM 表要快一个数量级，数据文件是存储在内存中。Memory表的结构在重启以后还会保留，但数据会丢失。Memroy表在很多场景可以发挥好的作用：

1、用于查找(lookup）或者映射(mapping）表，例如将邮编和州名映射的表。

2、用于缓存周期性聚合数据(periodically aggregated data)的结果。

3、用于保存数据分析中产生的中间数据。

Memory表支持 Hash索引，因此查找操作非常快。Memroy表是表级锁，因此并发写入的性能较低，每行的长度是固定的，可能导致部分内存的浪费。

9. **NDB集群引擎**

使用MySQL服务器、NDB集群存储引擎，以及分布式的、share-nothing 的、容灾的、高可用的NDB数据库的组合，被称为MySQL集群（MySQL Cluster)。

## MyISAM和InnoDB的区别是什么?

MyISAM引擎是5.1版本之前的默认引擎，支持**全文检索、压缩、空间函数**等，**但是不支持事务和行级锁**，所以一般用于有大量查询少量插入的场景来使用，而且MyISAM不支持外键，并且索引和数据是分开存储的。

InnoDB是**基于聚簇索引**建立的，和MyISAM相反，它支持事务、外键，并且通过MVCC来支持高并发，索引和数据存储在一起。

## 请概述下数据库的范式设计

目前关系数据库有**六种范式**，常见范式：

- 第一范式：1NF是对属性的**原子性约束**，要求属性具有原子性，不可再分解；**列原子化。**
- 第二范式：2NF是对记录的**唯一性约束**，要求记录有惟一标识，即实体的唯一性；**消除部份依赖。**
- 第三范式：3NF是对字段**冗余性的约束**，即任何字段不能由其他字段派生出来，它要求字段没有冗余。**消除传递依赖。**

**范式化设计优缺点:**

- 优点：可以尽量得减少数据冗余，使得更新快，体积小；

- 缺点：对于查询**需要多个表进行关联**，减少写得效率增加读得效率，更难进行索引优化

**反范式化：**

- 优点：可以减少表的关联，可以更好得进行索引优化；

- 缺点：数据冗余以及数据异常，数据得修改需要更多的成本，常见的反范式设计有**缓存**、冗余等等。

## 数据库表设计时，字段你会如何选择？

更小的通常更好，应该尽量使用可以正确存储数据的**最小数据类型**。更小的数据类型通常更快，因为它们占用更少的磁盘、内存和CPU缓存，并且处理时需要的CPU周期也更少。但是要确保没有低估需要存储的值的范围。

简单就好，简单数据类型的操作通常需要更少的CPU周期。例如，整型比字符操作代价更低，比如应该使用MySQL内建的类型而不是字符串来存储日期和时间。

**尽量避免NULL**，如果查询中包含可为NULL的列，对MySQL来说更难优化，因为**可为NULL的列使得索引、索引统计和值比较都更复杂。**可为NULL的列会使用更多的存储空间，在MySQL里也需要特殊处理。当可为NULL的列被索引时，每个索引记录需要一个额外的字节。

## mysql里记录货币用什么字段类型好？

MySQL既支持精确类型的存储DECIMAL类型，也支持不精确类型存储FLOAT和 DOUBLE类型。对于货币记录，应该**选择DECIMAL类型**，但是DECIMAL类型是以字符串形式存放的，所以性能会有影响。

作为替代方案，可以在数据量比较大的而且要求精度时，虑**使用BIGINT代替DECIMAL**，将需要存储的货币单位根据小数的位数乘以相应的倍数即可。

## 谈谈MySQL里的字符串类型

MySQL里的字符串类型有：SET、BLOB、ENUM、VARCHAR、CHAR、TEXT。VARCHAR和 CHAR是两种最主要的字符串类型。VARCHAR类型用于存储可变长字符串，大部分的业务情况下比定长类型更节省空间，CHAR类型是定长的，CHAR适合存储很短的字符串，或者所有值定长或都接近同一个长度。

使用BLOB和TEXT则要慎重，**一般把 BLOB或TEXT 列分离到单独的表中**，还可以对BLOB或TEXT 列使用**合成的(Synthetic?)索引**，就是根据大文本字段的内容建立一个散列值并单独存储在数据列中，可以通过检索散列值找到数据行。如果表中的字段的取值是固定几个字符串，可以使用枚举列代替常用的字符串类型。

## VARCHAR(M)最多能存储多少数据？

对于VARCHAR(M)类型的列最多可以定义**65535个字节**。其中的M代表该类型最多存储的字符数量，但在实际存储时并不能放这么多。

MySQL对一条记录占用的最大存储空间是有限制的，除了BLOB或者TEXT类型的列之外，其他所有的列（不包括隐藏列和记录头信息）占用的字节长度加起来不能超过65535个字节。所以MySQL服务器建议我们把存储类型改为TEXT或者BLOB的类型。这个65535个字节除了列本身的数据之外，还包括一些其他的数据，从行记录格式我们可以得知，**为了存储一个VARCHAR(M)类型的列**，其实需要占用3部分存储空间：**真实数据、真实数据占用字节的长度、NULL值标识**（如果该列有NOT NULL属性则可以没有这部分存储空间）。

我们假设表中只有一个VARCHAR字段的情况：

- 如果该VARCHAR类型的列**没有**NOT NULL属性，那最多只能存储65532个字节的数据，因为真实数据的长度可能占用2个字节，NULL值标识需要占用1个字节。


- 如果VARCHAR类型的列**有**NOT NULL属性，那最多只能存储65533个字节的数据，因为真实数据的长度可能占用2个字节，不需要NULL值标识。


如果VARCHAR(M)类型的列使用的不是ascii字符集，那M的最大取值取决于该字符集**表示一个字符最多需要的字节数**。在列的值允许为NULL的情况下，gbk字符集表示一个字符最多需要2个字节，那在该字符集下，M的最大取值就是32766（也就是：65532/2），也就是说最多能存储32766个字符；utf8字符集表示一个字符最多需要3个字节，那在该字符集下，M的最大取值就是21844，就是说最多能存储21844（也就是：65532/3）个字符。

不管如何，请牢记：MySQL**一个行中的所有列**（不包括隐藏列和记录头信息）占用的字节长度加起来不能超过65535个字节。

## 什么是虚拟生成列？

虚拟生成列又叫Generated Column，是MySQL 5.7引入的新特性，就是数据库中**这一列由其他列计算而得**。在MySQL 5.7中，支持两种Generated Column，即**Virtual Generated Column（虚拟生成的列）**和**Stored Generated Column（存储生成的列）**，二者含义如下：

1. **Virtual Generated Column（虚拟生成的列）**：不存储该列值，即MySQL只是将这一列的元信息保存在数据字典中，并不会将这一列数据持久化到磁盘上，而是当读取该行时，触发触发器对该列进行计算显示。

2. **Stored Generated Column（存储生成的列）**： 存储该列值，即该列值在插入或更新行时进行计算和存储。所以相对于Virtual Column列需要更多的磁盘空间，与Virtual Column相比并没有优势。因此，MySQL 5.7中，不指定Generated Column的类型，**默认是Virtual Column**，在表中允许Virtual Column和Stored Column的混合使用。

提高效率：由于mysql在普通索引上加函数会造成索引失效，造成查询性能下降，Generated Column（的**函数索引**）刚好可以解决这个问题，可以在Generated Column加上索引来提高效率。但是不能建立虚拟列和真实列的联合索引，同时虚拟列是不允许创建主键索引和全文索引。

创建虚拟生成列的语法：

```sql
CREATE TABLE `triangle` (
    `a` double DEFAULT NULL,
    `b` double DEFAULT NULL,
    `sidec` double GENERATED
    ALWAYS AS (
        SQRT(a * a + b * b)
    )
);

alter table triangle add column sided tinyint(1) generated always as (a*b) virtual;
```

## 请说下事务的基本特性

事务应该具有4个属性：**原子性、一致性、隔离性、持久性**。这四个属性通常称为ACID特性。

1. 原子性指的是一个事务中的操作要么全部成功，要么全部失败。


2. 一致性指的是**数据库总是从一个一致性的状态转换到另外一个一致性的状态**。比如A转账给B100块钱，假设中间sql执行过程中系统崩溃A也不会损失100块，因为事务没有提交，修改也就不会保存到数据库。

3. 隔离性指的是**一个事务的修改在最终提交前，对其他事务是不可见的。**

4. 持久性指的是事务一旦提交，所做的修改就会永久保存到数据库中。

## 事务并发可能引发什么问题？

1. 当一个事务读取到了另外一个事务修改但未提交的数据，被称为**脏读。**


2. 当事务内相同的记录被检索两次，且两次得到的结果不同时，此现象称为**不可重复读。**

3. 在事务执行过程中，事务2将**新记录**添加到正在读取的事务1中，导致事务1按照某个相同条件多次读取记录时，后读取时读到了之前没有读到的记录，发生**幻读。**

如果事务2中是删除了符合的记录而不是插入新记录，那事务1中之后再根据条件读取的记录变少了，在MySQL中这种现象不属于幻读，相当于对每一条记录都发生了不可重复读的现象。

## 请描述下MySQL中InnoDB支持的四种事务隔离和区别

1. **read uncommitted：**未提交读，可能发生脏读、不可重复读和幻读问题。
2. **read committed：**已提交读，**可能发生不可重复读和幻读**问题，但是**解决了脏读**问题。
3. **repeatable read：**可重复读，在SQL标准中**可能发生幻读**问题，但是**解决了脏读和不可重复读**的问题，但是MySQL通过MVCC基本解决了幻读问题。这也是MySQL的缺省隔离级别。
4. **serializable：**串行化读，脏读、不可重复读和幻读问题都不会发生。

## MySQL有哪些索引类型

- 从**数据结构角度**可分为：**B+树索引、哈希索引、以及FULLTEXT（即全文）索引**（现在MyISAM和InnoDB引擎都支持了，通过**倒排索引**实现）和R-Tree索引（用于对GIS数据类型创建SPATIAL索引）。

  > B+树索引包括聚集索引（包括主键索引、非空唯一索引、隐藏索引等）、辅助索引（即非聚集索引，包括普通索引、唯一索引、全文索引，前缀索引，联合索引，覆盖索引等）等。

- 从**物理存储角度**可分为聚集索引（clustered index）、非聚集索引（non-clustered index）；


- 从**逻辑角度**可分为主键索引、普通索引，或者单列索引、多列索引（联合索引）、唯一索引、非唯一索引等等。


## 简单描述MySQL各个索引的区别

索引是一种**特殊的文件**（InnoDB数据表上的**索引是表空间的一个组成部分**），它们**包含着对数据表里所有记录的引用指针**。

- **普通索引**（由关键字KEY或INDEX定义的索引）的**唯一任务是加快对数据的访问速度。**普通索引允许被索引的数据列包含重复的值。
- **唯一索引**：如果能确定某个数据列，将只包含彼此各不相同的值，在为这个数据列创建索引的时候就应该用关键字**UNIQUE**把它定义为一个**唯一索引。**也就是说，唯一索引可以保证数据记录的唯一性。

- **主键索引**：是一种特殊的唯一索引，在一张表中只能定义一个主键索引，**主键用于唯一标识一条记录**，使用关键字 **PRIMARY KEY** 来创建。

- **联合索引：**索引可以覆盖多个数据列，如像INDEX(columnA, columnB)索引，这就是联合索引。

## MySQL的索引对数据库的性能有什么影响

索引（Index）是帮助MySQL**高效获取数据**的数据结构，所以索引可以极大的**提高数据的查询速度。**

但是每建立一个索引都要为它建立一棵B+树，一棵很大的B+树由许多数据页组成会占据很多的存储空间。而且每次对表中的数据进增、删、改操作时，都需要去修改各个B+树索引，同时这些操作可能会对节点和记录的排序造成破坏，所以存储引擎需要额外的时间进行一些记录移位，页面分裂、页面回收的操作来维护好节点和记录的排序。如果我们建了许多索引，每个索引对应的B+树都要进行相关的维护操作，这必然会对性能造成影响。

## 为什么MySQL的索引要使用B+树而不是B树？

答案见下一小节

## InnoDB一棵B+树可以存放多少行数据？

**在实际的数据库中，一个节点可以存储的数据可以很多，为什么？**

计算机在存储数据的时候，有最小存储单元，这就好比我们今天进行现金的流通最小单位是一毛。在计算机中磁盘**存储数据最小单元是扇区**，一个扇区的大小是 512 字节，而文件系统（例如XFS/EXT4）他的最小单元是块，一个块的大小是 4k。

而对于我们的 **InnoDB 存储引擎**也有自己的**最小储存单元——页（Page）**，**一个页的大小是 16K**。Innodb 的所有数据文件（后缀为ibd的文件），他的大小始终都是 16384（16k）的整数倍。**数据表中的数据都是存储在页中的**，所以一个页中能存储多少行数据呢？假设一行数据的大小是 1k，那么一个页可以存放 **16 行**这样的数据。

对于B+树而言，只有叶子节点存放数据，**非叶子节点存放的是索引信息和下一层节点的指针信息**。一个页的非叶子节点能存放多少指针？其实这也很好算，我们假设主键 ID 为常用的bigint类型，长度为 8 字节，而**指针大小**在 InnoDB 源码中设置为 6 字节，这样（每个索引单元）一共14字节，我们一个页（16384字节）中能存放多少这样的单元，其实就代表有多少指针，即**16384 ÷ 14 = 1170个。**因此，**一个页中的非叶子节点最多可以容纳 1170 个指针。**

> 进而可以这样推断（没有看懂，貌似有误，这里是假定一个根节点包含1170个指针（从后续得知，每个节点都对应一个页）），一棵高度为2的B+树，存在一个根节点和若干个叶子节点，能存放 1170 * 16 = 18720条这样的数据记录（因为前面假设一个页可以存放16行）。根据同样的原理我们可以算出一个高度为 3 的 B+ 树可以存放：1170 * 1170 * 16 = 21902400 条这样的记录。

所以在 InnoDB 中 B+ 树高度一般为 1-3 层，就能满足千万级的数据存储。

那么**为什么MySQL的索引要使用B+树而不是B树？**

B树和B+树的最大区别就是，**B树不管叶子节点还是非叶子节点，都会保存数据**，这样导致在非叶子节点中能保存的**指针数量变少**（有些资料也称为扇出），指针少的情况下要保存大量数据，只能**增加树的高度**，导致 IO 操作变多，查询性能变低。

## HashMap适合做数据库索引吗？

1. hash表只能匹配是否相等，**不能实现范围查找；**
2. 当需要按照索引进行order by时，hash值没办法支持排序；
3. 组合索引可以支持部分索引查询，如(a,b,c)的组合索引，查询中只用到了a和b也可以查询的，如果使用hash表，组合索引会将几个字段合并hash，没办法支持部分索引；

4. 当数据量很大时，hash冲突的概率也会非常大。

## InnoDB中只有B+树索引吗？

InnoDB存储引擎不仅仅有B+树索引，它**还支持全文索引、哈希索引。**

InnoDB存储引擎内部自己去监控索引表，如果监控到某个索引经常用，那么就认为是**热数据**，然后内部自己创建一个hash索引，称之为**自适应哈希索引**( Adaptive Hash Index,AHI)。使用的哈希函数采用除法散列方式，其冲突机制采用链表方式。我们对这个自适应哈希索引能够**干预的地方很少，只能设定是否启用和分区个数。**

从MySQL5.6.x开始，InnoDB开始支持**全文检索，内部的实现机制就是倒排索引。**但是MySQL整体架构上对全文检索的支持并不好，而且限制很多，比如**每张表只能有一个全文检索的索引**，不支持没有单词界定符( delimiter）的语言，所以如果有大批量或者专门的全文检索需求，还是应该选择**专门的全文检索引擎。**

## 什么是密集索引和稀疏索引？

1. **密集索引的定义：**叶子节点保存的不只是键值，还保存了位于同一行记录里的**其他列的信息**，由于密集索引决定了表的**物理排列**顺序，一个表只有一个物理排列顺序，所以**一个表只能创建一个密集索引。**

   <img src="https://i-blog.csdnimg.cn/blog_migrate/910dd7ecddafccf2f220d2f6ad349292.png#pic_center" alt="img" style="zoom: 50%;" />

2. **稀疏索引：**叶子节点仅保存了**键位信息**以及**该行数据的地址**，有的稀疏索引只保存了键位信息机器**主键**。

myisam存储引擎，不管是主键索引，唯一键索引还是普通索引都是稀疏索引。**innodb存储引擎有且只有一个密集索引。**

所以，**在innodb存储引擎里，密集索引就是的聚簇索引，稀疏索引就是普通二级索引。**

## **为什么要用自增列作为主键？**

1. 如果我们定义了主键(PRIMARY KEY)，那么InnoDB会选择**主键**作为聚集索引。如果没有显式定义主键，则InnoDB会选择第一个**不包含有NULL值的唯一索引**作为主键索引。如果也没有这样的唯一索引，则InnoDB会选择内置6字节长的**ROWID**作为隐含的聚集索引（ROWID随着行记录的写入而主键递增，这个ROWID不像ORACLE的ROWID那样可引用，**是隐含的**）。

2. 数据记录本身被存于主索引一颗B+Tree的叶子节点上，这就要求**同一个叶子节点内**（**大小为一个内存页或磁盘页**）的各条数据记录按主键顺序存放。因此每当有一条新的记录插入时，MySQL会根据其主键将其**插入适当的节点和位置**（也是相当于适当的页中），如果页面达到**装载因子**（InnoDB默认为15/16），则开辟一个新的页（节点），（每个页对应一个叶子节点？没错）。

   **重点来啦：InnoDB 里的 B+ 树中的每个节点都是一个数据页。**理解这个点，很多问题就会迎刃而解。

   ![img](https://i-blog.csdnimg.cn/blog_migrate/6ef4f457de5596caa1ff2c679c9c4a63.png)

3. 如果表使用**自增主键**，那么每次插入新的记录，记录就会顺序添加到当前索引节点的后续位置。当一页写满，就会自动开辟一个新的页。

4. 如果使用**非自增主键**（如果身份证号或学号等），由于**每次插入主键的值近似于随机**，因此每次新纪录都要被插到现有索引页的**中间某个位置**。此时MySQL不得不为了将新记录插到合适位置而移动数据，甚至目标页面可能已经被回写到磁盘上而从缓存中清掉，此时又要从磁盘上读回来，这无疑**增加了很多开销**。同时频繁的移动、分页操作会造成了大量的碎片，得到了不够紧凑的索引结构，后续不得不通过OPTIMIZE TABLE来重建表并优化填充页面。

## 主键和唯一键有什么区别？

1. 主键不能重复，不能为空，唯一键不能重复，可以为空。
2. 建立主键的目的是让外键来引用。
3. 一个表最多只有一个主键，但可以有很多唯一键。


## 说说对SQL语句优化有哪些方法？（选择几条）

（1）Where子句中，**表之间的连接条件**必须写在其他Where条件之前，那些可以过滤掉最大数量记录的条件（如>=,<=等范围条件）必须写在Where子句的末尾。HAVING最后再执行。

（2）用EXISTS替代IN、用NOT EXISTS替代NOT IN。

（3）避免在索引列上使用计算。

（4）避免在索引列上使用IS NULL和IS NOT NULL

（5）对查询进行优化，应尽量**避免全表扫描，首先应考虑在 where 及 order by 涉及的列上建立索引。**

（6）应尽量避免在 where 子句中对字段进行 null 值判断，否则将导致引擎放弃使用索引而进行全表扫描。

（7）应尽量避免在 where 子句中对字段进行**表达式操作**，这将导致引擎放弃使用索引而进行全表扫描。

## 如何提高insert的性能？

**答：有如下方法。**

1. 合并多条 insert 为一条，即： insert into t values(a,b,c),  (d,e,f) ,,,

   原因分析：主要原因是多条insert合并后日志量（MySQL的binlog和innodb的事务日志） 减少了，降低**日志刷盘**的数据量和频率，从而提高效率。通过合并SQL语句，同时也能减少SQL语句解析的次数，**减少网络传输的IO。**

2. 修改参数**bulk_insert_buffer_size**， 调大**批量插入的缓存**；

3. 设置 innodb_flush_log_at_trx_commit = 0 ，相对于 innodb_flush_log_at_trx_commit = 1可以十分**明显的提升导入速度**。

   innodb_flush_log_at_trx_commit是**配置MySql日志何时写入硬盘**的参数，该参数对 InnoDB Log 的写入性能有非常关键的影响，可以设置为**0，1，2，**解释如下：

   - **0**：log buffer中的数据将以**每秒一次**的频率写入到log file中，同时进行log file的flush（刷到磁盘）操作。但是在该模式下，每个事务的提交并不会触发任何 log buffer 到 log file 的刷新或者文件系统（也是log file）到磁盘的刷新操作；

   - **1**：**每次事务提交**时都会把log buffer中的数据写入到log file，同时也会触发文件系统（log file）到磁盘的同步，即flush(刷到磁盘中去）操作。**该模式为系统默认。**

   - **2**：每次事务提交时都会把log buffer的数据写入log file，但是flush(刷到磁盘)操作并不会同时进行。该模式下，MySQL会**每秒执行一次** flush(刷到磁盘)操作。

4. **手动使用事务**

   因为MySQL 默认开启**事务自动提交**模式（autocommit=ON）。这样**每插入一条数据**，都会进行一次commit。所以，为了减少创建事务的消耗，我们可以手动使用事务，即`START TRANSACTION;insert...,insert...;commit`；即执行多个insert后再一起提交。一般1000条insert提交一次。

## 什么是覆盖索引？什么是回表查询？

InnoDb存储引擎有两大类索引，聚集索引和非聚集索引（也称辅助/二级索引），聚簇索引的叶子节点存储行记录，因此**InnoDb必须要有聚簇索引且仅有一个聚簇索引**，而辅助索引的叶子节点只存储**索引值**和**主键值**。所以，通过聚簇索引一次性能获取所有列的数据，辅助索引一般不行。当我们SQL语句中的列无法在普通索引中获得时，就需要通过主键值到聚簇索引中获取相关的数据，这个过程就被称为回表。

而如果我们使用**联合索引**，使得SQL所需的所有列数据在这个索引上就能获得时，我们称为发生了**索引覆盖**或者**覆盖索引**。

## 什么是三星索引？

对于一个查询而言，一个三星索引，可能是其最好的索引。

如果查询使用三星索引，一次查询通常只需要进行一次磁盘随机读以及一次窄索引片的扫描，因此其相应时间通常比使用一个普通索引的响应时间少几个数量级。

- **相关性星**：一个查询相关的**索引行是相邻的**或者至少**相距足够靠近**的则获得一星。

  > 隐含点：只有where后的条件是等号相连，行才会相邻

- **排序星**：如果索引中的数据顺序和查找中的排列顺序一致则获得二星。

- **覆盖索引星**：如果索引中的列包含了查询中需要的全部列则获得三星。

三星索引在实际的业务中如果无法同时达到，一般我们认为**第三颗星最重要**，第一和第二颗星重要性差不多，根据业务情况调整这两颗星的优先度。

## 大表关联查询优化

一个6亿的表a，一个3亿的表b，**通过tid关联**，你如何最快的查询出满足条件的第50000到第50200中的这200条数据记录？

1. 如果A表**TID是自增长**，并且**是连续的**，B表的ID为索引。

   ```sql
   select * 
   from a,b 
   where a.tid = b.id and a.tid > 500000 limit 200;
   ```

2. 如果A表的**TID不是连续的**，那么就需要使用覆盖索引。TID要么是主键，要么是辅助索引，B表ID也需要有索引。

   ```sql
   select * 
   from a,b 
   where a.tid = b.id and a.tid > 500000 limit 200;
   ```

## [SELECT *] 和 [SELECT 全部字段] 有何优缺点？

1. 前者要**解析数据字典**，后者不需要。
2. 结果输出顺序：前者与建表列顺序相同，后者按指定字段顺序。

3. 表字段改名：前者不需要修改，后者需要改。

4. 后者可以建立索引进行优化，前者无法优化。

5. 后者的可读性比前者要高。

## 请概述下什么是MySQL的分区表

表的分区，是指根据一定规则，**将数据库中的一张表分解成多个更小的、容易管理的部分。**从逻辑上看，只有一张表，但是**底层却是由多个物理分区组成。**

1. **表分区与分表的区别**
   - 分表：指的是通过一定规则，将一张表分解成多张不同的表。比如将用户订单记录根据时间成多个表。
   - 分表与分区的区别在于：**分区从逻辑上来讲只有一张表**，而分表则是将一张表分解成多张表。

2. **表分区的好处**
   - **存储更多数据：**分区表的数据可以**分布在不同的物理设备上**，从而高效地利用多个硬件设备。和单个磁盘或者文件系统相比，可以存储更多数据。
   
   - **优化查询：**在where语句中包含分区条件时，可以只扫描一个或多个分区表来**提高查询效率**。涉及sum和count语句时，也可以在多个分区上**并行处理**，最后汇总结果。
   
   - **分区表更容易维护：**例如，想批量删除大量数据可以清除整个分区。
   
3. **分区表的限制因素**

   - 一个表最多只能有1024个分区。

   - 如果分区字段中有主键或者唯一索引的列，那么**有主键列和唯一索引列都必须包含进来**。即分区字段要么不包含主键或者索引列，要么包含全部主键和索引列。


   - 分区表中**无法使用外键约束。**


   - MySQL的分区**适用于一个表的所有数据和索引**，不能只对表数据分区而不对索引分区，也不能只对索引分区而不对表分区，也不能只对表的一部分数据分区。


4. **分区表的类型**

   - **RANGE分区：** 这种模式允许将数据划分不同范围。例如可以将一个表**按照年份**划分成若干个分区。

   - **LIST分区：** 这种模式允许系统**通过预定义的列表的值来对数据进行分割**。按照List中的值分区，与RANGE的区别是，range分区的区间范围值是连续的。

   - **HASH分区：**这中模式允许通过对表的一个或多个列的Hash Key进行计算，最后通过这个Hash码的不同数值对应的数据区域进行分区。例如可以建立一个对表的主键进行分区的表。

   - **KEY分区：**这是上面Hash模式的一种延伸，**这里的Hash Key是MySQL系统产生的。**

   - **Column分区：**需要和RANGE和List结合，支持字符串和日期的分区，也支持多列分区。

   - **复合分区/子分区**：分区之下还可以再分区。

5. **在实际工作中用分区表比较少**

   - 分区表、分区键设计不太灵活，如果不走分区键，很容易出现全表锁。

   - 自己分库分表（注意不是分区），自己可以掌控业务场景与访问模式。但是如果使用分区表，研发写了一个sql，都不确定mysql是怎么操作的，不太可控。


   - 分区表无论怎么分，都是在一台机器上（？不是可以分布在不同的物理设备上吗），天然就**有性能的上限。**

## 说几条MySQL对SQL的执行做的优化手段

1. **对SQL语句的优化**

   1. MySQL会对我们的**SQL语句做重写**，包括条件化简，比如常量传递、除没用的条件等等。
   2. 还会将一些**外连接转换为内连接**，然后选择成本最低的方式执行。
   3. **对IN子查询会进行物化**，物化表转连接查询、转换为半连接等方式进行。

2. 在SQL语句的执行过程中，MySQL引入了**索引条件下推**，ICP 的目标是**将部分查询条件下推到索引扫描阶段**，减少回表操作的次数。

   > 索引条件下推的核心思想是：在索引扫描阶段，尽可能多地过滤数据，减少回表次数。
   >
   > **具体过程：**
   >
   > 1. 查询中有部分条件可以直接作用于索引的键值（如范围查询、等值查询）。
   > 2. 存储引擎在索引扫描阶段应用这些条件进行初步过滤。
   > 3. 仅对满足索引条件的数据进行回表操作，获取完整行记录后再应用剩余的查询条件。
   >
   > **示例：**
   >
   > ```sql
   > CREATE TABLE orders (
   >     id INT NOT NULL PRIMARY KEY,
   >     order_date DATE NOT NULL,
   >     total_amount DECIMAL(10, 2),
   >     customer_id INT,
   >     INDEX idx_order_date_amount (order_date, total_amount)
   > );
   > 
   > -- 查询
   > SELECT * FROM orders 
   > WHERE order_date >= '2025-01-01' AND total_amount > 1000;
   > ```
   >
   > **优化前（无 ICP）：**
   >
   > 1. 使用索引扫描满足 `order_date >= '2025-01-01'` 的记录。
   > 2. 回表获取完整的行数据。
   > 3. 应用 `total_amount > 1000` 条件进行过滤。
   >
   > **优化后（有 ICP）：**
   >
   > 1. 使用索引扫描时，**直接在索引阶段应用** `order_date >= '2025-01-01'` 和 `total_amount > 1000` 条件。
   > 2. 仅对满足所有索引条件的数据回表。
   >
   > **适用场景**
   >
   > 索引条件下推适用于**查询条件中包含复合索引**的列，并且这些条件可以在索引扫描时直接使用。
   >
   > **适用的典型条件：**
   >
   > - 索引列的范围查询（如 `BETWEEN`、`>=`、`<=`）。
   > - 组合查询条件（复合索引的多列过滤）。
   > - 包含部分索引列的 `LIKE` 查询。
   >
   > **不适用的情况：**
   >
   > - 查询条件中包含**无法作用于索引**的部分，如对非索引列的过滤。
   > - 函数或表达式作用于索引列时（如 `YEAR(order_date) = 2025`）。
   >
   > **如何确认是否使用 ICP**
   >
   > 可以通过 MySQL 的 **`EXPLAIN`** 命令查看查询的执行计划，判断是否启用了索引条件下推。
   >
   > #### 示例：
   >
   > ```sql
   > EXPLAIN SELECT * FROM orders WHERE order_date >= '2025-01-01' AND total_amount > 1000;
   > ```
   >
   > 在执行计划中，`Extra` 列会显示 `Using index condition`，表示启用了索引条件下推。

   例如，where后面的多个搜索条件都使用到了一个二级索引列，这些搜索条件中虽然出现了索引列，有些却不能使用到索引，像**like ‘%...’**查询。MySQL为了避免不必要的回表，**从二级索引取得的索引记录，先做条件判断，如果条件不满足，则该二级索引记录不会去回表**，这样可以大量的减少回表操作的随机IO成本。

3. 在**回表操作**上，因为每次执行回表操作时都相当于要随机读取一个聚簇索引页面，而这些随机IO带来的性能开销比较大。MySQL中提出了一个名为**Disk-Sweep Multi-Range Read(MRR，多范围读取)**的优化措施，即先读取一部分二级索引记录，将它们的主键值排好序之后再统一执行回表操作。

   > **多范围读取**是一种优化读取磁盘数据的技术，旨在通过**减少随机磁盘访问次数**来提高 I/O 性能。
   >
   > 1. **背景**
   >
   > 在传统的多范围查询中，数据库需要**扫描多个范围**（如索引范围）并读取对应的数据。如果这些范围内的数据在磁盘上并不连续，那么会产生大量的随机 I/O，影响性能。
   >
   > **例子：**
   >
   > ```sql
   > SELECT * FROM table 
   > WHERE id BETWEEN 100 AND 200 
   >    OR id BETWEEN 500 AND 600;
   > ```
   >
   > 这种查询涉及多个范围 `id BETWEEN 100 AND 200` 和 `id BETWEEN 500 AND 600`，如果每次查询都直接读取范围内的行，很可能导致**频繁的磁盘寻道。**
   >
   > ------
   >
   > 2. **Disk-Sweep Multi-Range Read 的工作原理**
   >
   > Disk-Sweep Multi-Range Read 通过以下方式优化读取流程：
   >
   > （1）**将范围查询结果排序**
   >
   > - 首先，根据查询条件**扫描索引范围**，获取满足条件的行地址（例如磁盘页的物理位置）。
   > - 然后，**将这些地址按照磁盘物理位置排序。**
   >
   > （2）**按顺序读取磁盘数据**
   >
   > - 根据排序结果，**顺序读取磁盘上的数据块**，减少磁盘的随机访问。
   > - 这种顺序读的方式利用了磁盘的特性（**顺序读比随机读快很多**），从而提高了 I/O 性能。
   >
   > （3）**缓存机制优化**
   >
   > - 在读取数据时，尽可能利用数据库的缓存（如 InnoDB 的缓冲池）来**减少重复读取磁盘数据。**
   >
   > 3. **适用场景**
   >
   > Disk-Sweep Multi-Range Read 技术主要适用于以下场景：
   >
   > （1）**多范围查询**
   >
   > 如 `WHERE id IN (...)` 或 `WHERE column BETWEEN ... OR column BETWEEN ...`。
   >
   > （2）**非连续索引匹配**
   >
   > 查询条件涉及多个不连续的索引范围，例如通过 `OR` 条件或复杂逻辑产生的索引扫描结果。
   >
   > （3）**大数据集读取**
   >
   > 当查询结果涉及的数据量较大时，减少随机 I/O 的影响尤为重要。
   >
   > 4. **MySQL 中的实现**
   >
   > 在 MySQL 的 InnoDB 存储引擎中，Disk-Sweep Multi-Range Read 是通过**优化多范围扫描**来实现的。查询执行计划中的 `EXTRA` 列可能显示类似 `Using MRR` 的信息，表示启用了 Multi-Range Read。
   >
   > **示例查询和分析**
   >
   > ```sql
   > EXPLAIN SELECT * FROM orders 
   > WHERE customer_id BETWEEN 1000 AND 2000 
   >    OR customer_id BETWEEN 5000 AND 6000;
   > ```
   >
   > 执行计划中的 `Using MRR` 表示 MySQL 在该查询中启用了 Multi-Range Read 优化。

4. MySQL在一般情况下执行一个查询时最多只会用到**单个二级索引**，但存在有特殊情况，也可能**在一个查询中使用到多个二级索引**，然后就会进行**索引合并**，比如Intersection交集合并、Union索引合并、Sort-Union合并（排序联合）。

## InnoDB引擎的三大特性是什么？

InnoDB的三大特性是：**自适应Hash索引、Buffer Pool、双写缓冲区。**

1. **自适应Hash索引：**InnoDB存储引擎**内部自己去监控索引表**，如果监控到某个索引经常用，那么就认为是**热数据**，然后内部自己创建一个hash索引，称之为自适应哈希索引( Adaptive Hash Index,AHI)，创建以后，如果下次又查询到这个索引，那么直接通过hash算法推导出记录的地址，直接一次就能查到数据。InnoDB存储引擎使用的哈希函数采用**除法散列方式**，其**冲突机制采用链表方式。**

2. **Buffer Pool：**为了提高访问速度，MySQL服务器预先（在启动时）就分配/准备了许多这样的**内存空间**，为的就是与MySQL数据文件中的页做交换，来把数据文件中的页（也就是磁盘中的页）放到事先准备好的内存中。数据的访问是按照页（默认为16KB）的方式从数据文件中读取到 buffer pool中。Buffer Pool按照**最近最少使用算法（LRU）**，来管理内存中的页。

   Buffer Pool实例允许有多个，每个实例都有一个专门的**mutex(互斥锁)**保护。Buffer Pool中缓存的数据页类型有：索引页、数据页、undo页、插入缓冲（insert buffer)、自适应哈希索引、InnoDB存储的锁信息、数据字典信息（data dictionary）等等。

3. **双写缓冲区：**这是一个位于**系统表空间**的存储区域。在写入时，InnoDB先把从缓存池中的得到的页写入系统表空间的双写缓冲区，之后再把页写到.ibd数据文件中相应的位置。如果在页写入数据文件（磁盘）的过程中发生意外崩溃，InnoDB在稍后的恢复过程中在doublewrite buffer中找到完好的page副本用于恢复就可以了。

   doublewrite是顺序写，开销比较小，所以在正常的情况下，MySQL写数据page时，会写两遍到磁盘上，第一遍是写到doublewrite buffer，第二遍是从doublewrite buffer写到真正的数据文件中。

   它的作用主要是为了避免**partial page write(部分页写入)**的问题。因为InnoDB的page size一般是16KB，校验和写入到磁盘是以page页为单位进行的，而操作系统写文件是以4KB作为单位的。因此可以得出**每写一个page页，操作系统需要写4个块**，如果中间发生了系统断电或系统崩溃，就会导致只有一部分页是写入成功的，这时page数据就会出现不一样的情形，从而形成一个"断裂"的page，使数据产生混乱。

## redolog和binlog的区别是什么？

答案见下一题

## MySQL崩溃后的恢复为什么使用redolog而不用binlog？

1. **这两者使用方式不一样**

   - **binlog会记录表所有的更改操作**，包括更新/删除数据，更改表结构等等，**主要用于人工恢复数据**。

   - 而**redo log对于我们是不可见的**，它是 InnoDB 用于保证crash-safe能力的（即系统在突发的宕机或者崩溃情况发生时，对数据的安全性进行保护），也就是在事务提交后如果MySQL崩溃的话，可以保证事务的持久性，即**事务提交后其更改是永久性的。**

   **一句话概括：binlog 是用作人工恢复数据，redo log 是 MySQL 自己使用，用于保证在数据库崩溃时的事务持久性。**

2. redo log 是 InnoDB 引擎特有的，binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用。

3. **redo log是物理日志**，记录的是“在某个**数据页**上做了什么修改”，恢复的速度更快；**binlog是逻辑日志**，记录的是这个语句的**原始逻辑**，比如“给ID=2这的c字段加1 ”。

   binlog有三种日志记录格式Statement、Row、混合模式。

   - Statement格式：记录**SQL语句本身**，可以直观地查看每一个操作。
   - Row格式：记录行级的变更，即**每一行数据在操作前后的状态。**
   - Mixed格式：根据具体操作自动选择Statement或Row格式。

4. redo log是**循环写**的日志文件，redo log只会记录**未刷盘**的日志，已经刷入磁盘的数据都会从redo log这个有限大小的日志文件里删除；而**binlog 是追加日志**，保存的是全量的日志。

5. 最重要的是，当数据库**crash**后，想要恢复**未刷盘但已经写入**redo log 和 binlog 的数据到内存时，**binlog 是无法恢复的**。虽然 binlog 拥有全量的日志，但没有一个标志让 innoDB 判断哪些数据已经写入磁盘，哪些数据还没有。

   比如，binlog 记录了两条日志：

   - 给 ID=2 这一行的 c 字段加1

   - 给 ID=2 这一行的 c 字段加1

   在记录1入表后，记录2未入表时，数据库crash。重启后，只通过 binlog 数据库**无法判断这两条记录哪条已经写入磁盘，哪条没有写入磁盘**。不管是两条都恢复至内存，还是都不恢复，对 ID=2 这行数据来说都不对（因为无法恢复到之前）。

   但 redo log 不一样，（事务提交成功），**只要是刷入磁盘的数据，都会从 redo log 中抹掉**。数据库重启后，只要把 redo log 中的数据都恢复至内存就可以了。

## MySQL如何实现事务的ACID？

参见下个问题。

## InnoDB事务是如何通过日志来实现的？

总的来说：

- 事务的**原子性**是通过 undo log 来实现的；
- 事务的**隔离性**是通过 读写锁 + MVCC 来实现的。事物的不可见性（即一个事务所做的修改操作在提交事务之前，对于其他事务来说是不可见的）。
- 事务的**持久性**是通过 redo log 来实现的；

- 事务的**一致性**通过原子性、隔离性、持久性来保证。

也就是说ACID四大特性之中：**C(一致性)是目的，A(原子性)、I(隔离性)、D(持久性)是手段，**是为了保证一致性，数据库提供的手段。数据库必须要实现AID三大特性，才有可能实现一致性。同时一致性也需要应用程序的支持，应用程序在事务里故意写出违反约束的代码，一致性还是无法保证的。例如，转账代码里从A账户扣钱而不给B账户加钱，那一致性还是无法保证。

至于InnoDB事务是如何通过日志来实现的，**简单来说：**

- 事务在修改页时，要记录undo日志，在记录undo之前要先记录undo的redo日志；

- 然后才修改数据页，再记录数据页修改的redo。

 **redo日志(里面包括undo的修改)一定要比数据页先持久化到磁盘。**

当事务需要回滚时，因为有undo，可以把数据页回滚到前（版本）镜像的状态。

崩溃恢复时，如果redo log中的事务没有对应的commit记录，那么需要用undo把该事务的修改回滚到事务开始之前；如果有commit记录，就用redo日志滚到该事务完成时并提交掉。

**更详细的回答是：**

- redo通常是**物理日志，记录的是页的物理修改操作，用于恢复提交事务修改的页操作。**

- 而undo是**逻辑日志**，根据**每行**记录进行记录，用来**回滚记录到某个特定的版本。**

当**事务提交之后**会把所有**修改信息**存到redo日志中。redo日志由两部分组成：一个是在**内存里的redo log buffer**，另一个是在**磁盘里的redo log文件。**mysql 为了提升性能不会把每次的修改都实时同步到磁盘，而是会**先存到Buffer Pool(缓冲池)里头**，把这个当作缓存来用。然后**使用后台线程去做缓冲池和磁盘之间的同步。**系统重启后读取redo log日志恢复最新数据。

虽然**redo log会在事务提交前做一次磁盘写入**，但是这种IO操作相比于buffer pool这种以页（16kb）为管理单位的随机写入，它做的是**几个字节的顺序写入**，效率要高得多。redo log buffer中的数据，会在一个**合适的时间点**刷入到磁盘中。这个合适的时间点包括：

1. MySQL 正常关闭的时候；
2. MySQL 的后台线程**每隔一段时间定时**的将 redo log buffer 刷入到磁盘，**默认是每隔 1s 刷一次；**
3. 当redo log buffer中的日志写入量超过 redo log buffer **内存的一半**时，即超过 8MB 时，会触发 redo log buffer 的刷盘；
4. 当事务提交时，根据配置的参数 `innodb_flush_log_at_trx_commit` 来决定是否刷盘。要**严格保证数据不丢失**，必须得保证 `innodb_flush_log_at_trx_commit` 配置为 1（这是**系统默认的模式**）。

redo log在进行**数据重做**时，只有读到了**commit标识**，才会认为这条redo log日志是完整的，才会进行数据重做，否则会认为这个redo log日志不完整，不会进行数据重做。

undo log 和 redo log不一样，它是**逻辑日志**。可以认为：

- 当delete一条记录时，undo log中会记录一条对应的insert记录，反之亦然。

- 当update一条记录时，它会记录一条对应相反的update记录。
- 当执行回滚时，就可以从undo log中的**逻辑记录**读取到相应的内容并进行回滚。

而事务的**隔离性**，也可以通过undo log来实现的：当读取的某一行数据被其他事务锁定时，它可以从undo log中分析出该行记录以前的数据（版本）是什么，从而提供该行版本信息，帮助用户实现一致性**非锁定读取**，这也是MVCC的实现机制的组成部分。

## 什么是当前读和快照读？

- **当前读：**也叫锁定读。像select lock in share  mode(共享锁), select for update ; update, insert ,delete(排他锁)这些操作都是一种当前读。它**读取的是记录的最新版本**，读取时还要保证其他并发事务不能修改当前记录，因此会对读取的记录进行加锁。是一种**悲观锁**的实现。

- **快照读：**是一种无锁读。像不加锁的select操作就是快照读，即不加锁的非阻塞读；快照读的前提是隔离级别**不是串行级别**，串行级别下的快照读会退化成当前读；之所以出现快照读的情况，是基于提高并发性能的考虑，快照读的实现是基于多版本并发控制，即MVCC。快照读指的是通过 MVCC 机制读取**历史版本**的数据快照（也就是**历史版本数据**），而不是读取数据的最新版本。

  > 注意：快照读往往读取的是数据的历史版本，但并不是一定读取历史版本，有可能读取的是数据的最新版本。

## 什么是MVCC？

**MVCC**（Multi-Version Concurrency Control），叫做**基于多版本的并发控制协议**。他是和**LBCC**（Lock-Based Concurrency Control）**基于锁的并发控制协议**的概念是相对的。**MVCC是乐观锁的一种实现方式**，它在很多情况下，**避免了加锁操作，降低了开销**。既然是基于多版本，即快照读可能读到的并不一定是数据的最新版本，很有可能是之前的历史版本。

MVCC最大的好处是：**读不加锁，并且读写不冲突**。在读多写少的OLTP应用中，读写不冲突是非常重要的，极大的增加了系统的并发性能，现阶段几乎所有的RDBMS包括MySQL，都支持了MVCC。

## MVCC的底层实现原理是什么？

MVCC实现原理主要是依赖记录中的**隐式字段**、undo日志、Read View来实现的。

MySQL中**每行记录**除了我们自定义的字段外，还有数据库隐式定义的DB_TRX_ID、DB_ROLL_PTR、DB_ROW_ID等字段。

- DB_TRX_ID是最近修改/插入的**事务的ID**，即活跃事务id，记录了创建这条记录或者最后一次修改该记录的**事务ID。**
- DB_ROLL_PTR是**回滚指针**，用于配合undo日志，指向这条记录的**上一个版本。**
- DB_ROW_ID是非必须的。

不同事务或者相同事务对同一记录的修改，会导致该记录的undo log成为一条记录版本的线性链表，也就是**版本链**。

事务进行**快照读操作的时候产生一个Read View**，记录并维护系统当前**活跃事务的ID**，因为当每个事务开启时，都会被分配一个ID，这个ID是递增的，所以越是最新的事务，ID值越大。

Read View主要是将要被修改的数据的最新记录中的DB_TRX_ID（即当前事务ID）取出来，与系统当前其他活跃事务的ID去对比（由Read View维护），如果DB_TRX_ID跟Read View的属性做了**某些比较**，不符合可见性，那就通过DB_ROLL_PTR(回滚指针)去取出Undo Log中的DB_TRX_ID再比较，即遍历链表的DB_TRX_ID（从链首到链尾，即**从最近的一次修改查起**），直到找到满足特定条件的DB_TRX_ID，那么这个DB_TRX_ID所在的旧记录就是当前事务能看见的最新的旧版本。

> 1. **可见性（Visibility）的定义**
>
> 可见性指的是，当前事务在执行查询时，**哪些版本的数据可以被“看到”，即被读取。**
>
> 在 MVCC 模式下，数据的每次修改都会生成一个新版本，同时保留旧版本（通过 `undo log`）。当前事务在查询时，并不一定能看到数据的最新版本，而是**通过可见性规则决定能看到哪个版本。**
>
> 2. **可见性判断规则**
>
> 当查询某条记录时，InnoDB 会将数据版本的 `DB_TRX_ID` （当前数据的最新版本的事务id）与 `Read View` 中的事务信息进行比较，**以决定该数据版本是否对当前事务可见。**具体规则如下：
>
> 1. **规则 1**：如果 `DB_TRX_ID` < `trx_id_min_active`，说明修改该版本的事务在创建 `Read View` 之前已经提交，因此该版本**可见**。
> 2. **规则 2**：如果 `DB_TRX_ID` ≥ `trx_id_max_active`，说明修改该版本的事务在创建 `Read View` 之后才开始，因此该版本**不可见**。
> 3. **规则 3**：如果 `DB_TRX_ID` 在 `[trx_id_min_active, trx_id_max_active)` 范围内：
>    - 如果 `DB_TRX_ID` 不在 `trx_ids_active_list` 中（说明该事务已经提交），则该版本**可见**。
>    - 如果 `DB_TRX_ID` 在 `trx_ids_active_list` 中（即作为集合的一个元素，说明该事务未提交），则该版本**不可见**。

正是因为RC、RR隔离级别下Read View**生成时机**的不同，造成RC、RR级别下快照读的结果的不同。

- RC隔离级别（已提交读）下，是**每个快照读都会**生成一个最新的Read View。也就是说在事务中，**每次快照读**都会生成一个新的快照和**新的Read View**，这就是我们在RC级别下的事务中可以看到**别的事务提交的更新**的原因。

  > **行为特性**
  >
  > - **每次快照读都会生成一个新的 Read View**。
  > - 每次生成的 Read View 都会反映当前系统中**活跃事务的最新状态。**
  > - 由于 Read View 是动态生成的，每次快照读都能看到**其他事务最新提交的结果。**
  >
  > **结果特性**
  >
  > - 当前事务可以读取到**其他事务已提交**的最新数据。
  > - 数据一致性仅保证当前读取的那一瞬间，不保证**同一事务中多次读取**的结果一致（因为 Read View 会随每次读取更新）。
  >
  > **场景示例**
  >
  > ```sql
  > -- 假设事务 A 在此时开始：
  > START TRANSACTION;
  > 
  > -- 第一次快照读，生成 Read View1
  > SELECT * FROM orders WHERE customer_id = 1;
  > 
  > -- 另一事务 B 提交了一条修改
  > UPDATE orders SET amount = 200 WHERE customer_id = 1;
  > COMMIT;  -- 事务 B 提交
  > 
  > -- 第二次快照读，生成 Read View2，能看到事务 B 提交的结果
  > SELECT * FROM orders WHERE customer_id = 1;
  > 
  > COMMIT;  -- 事务 A 提交
  > ```
  >
  > 在 `RC` 隔离级别下：
  >
  > - 第一次 `SELECT` 使用的 Read View1 不能看到事务 B 的修改。
  > - 第二次 `SELECT` 使用新的 Read View2，可以看到事务 B 的提交结果。
  >
  > #### **总结**
  >
  > - **Read View 的生成**：每次快照读时生成新的 Read View。
  > - **结果一致性**：无法保证事务中多次读取的结果一致。

- 而在RR隔离级别（可重复读）下，则是同一个事务中只有**第一个快照读**才会创建Read View，之后的快照读获取的都是同一个Read View，快照读生成Read View时，会记录此时所有其他活动事务的快照，其他事务的修改对于当前事务都是不可见的。而早于Read View创建的事务所做的修改均是可见。

  > **行为特性**
  >
  > - **在一个事务中，只有第一次快照读会生成一个 Read View**。
  > - 之后的所有快照读都使用相同的 Read View。
  > - 该 Read View 记录了事务开始时的系统状态，对应的快照将反映当时的活跃事务列表。
  >
  > **结果特性**
  >
  > - 快照读在**整个事务中保持一致**，即使其他事务提交了数据修改，也不会影响当前事务的快照读结果。
  > - 事务中多次快照读返回的数据一致，**保证了“可重复读”。**
  >
  > **场景示例**
  >
  > ```sql
  > -- 假设事务 A 在此时开始：
  > START TRANSACTION;
  > 
  > -- 第一次快照读，生成 Read View1
  > SELECT * FROM orders WHERE customer_id = 1;
  > 
  > -- 另一事务 B 提交了一条修改
  > UPDATE orders SET amount = 200 WHERE customer_id = 1;
  > COMMIT;  -- 事务 B 提交
  > 
  > -- 第二次快照读，仍然使用 Read View1，无法看到事务 B 提交的结果
  > SELECT * FROM orders WHERE customer_id = 1;
  > 
  > COMMIT;  -- 事务 A 提交
  > ```
  >
  > 在 `RR` 隔离级别下：
  >
  > - 第一次 `SELECT` 使用的 Read View1 会记录事务 B 的活动状态。
  > - 第二次 `SELECT` 仍然使用 Read View1，因此看不到事务 B 的提交结果。
  >
  > **总结**
  >
  > - **Read View 的生成**：事务中第一次快照读时生成。
  > - **结果一致性**：保证事务中多次读取的结果一致。

## 什么是锁？MySQL 中提供了几类锁？

锁是实现数据库并发控制的重要手段，可以保证数据库在多人同时操作时能够正常运行。MySQL 提供了**全局锁、行级锁、表级锁**。其中 **InnoDB 支持表级锁和行级锁**，MyISAM 只支持表级锁。

## 什么是全局锁、共享锁、排它锁？

- **全局锁**就是**对整个数据库实例加锁**，它的典型使用场景就是做**全库逻辑备份**。 这个命令可以使整个库处于只读状态。使用该命令之后，数据更新语句、数据定义语句、更新类事务的提交语句等操作都会被阻塞。

- **共享锁**又称读锁 (read lock)，是读取操作创建的锁。其他用户**可以并发读取**数据，但任何事务都**不能对数据进行修改**（获取数据上的排他锁），直到已释放所有共享锁。当然如果事务对读锁进行修改操作，很可能会造成**死锁。**

  > 如果事务T对数据A加上共享锁后，则**其他事务只能对A再加共享锁，不能加排他锁**。获准共享锁的所有事务只能读数据，不能修改数据。

- **排他锁** exclusive lock（也叫 writer lock）又称**写锁。**若某个事物对某一行加上了排他锁，只能这个事务对其进行读写，在此事务结束之前，其他事务不能对其进行加任何锁。**其他进程可以读取数据（指快照读）**，不能进行写操作，需等待其释放。**排它锁是悲观锁的一种实现。**

  > “其他进程可以读取”指的是快照读，即普通的 select 查询，因为普通的 select 不加任何锁。如果是当前读，那是不被允许的，因为当前读需要获取锁。
  >
  > 总结：写锁仅仅是阻止其他事务施加读/写锁，而不是禁止其他事务**读取数据**。例如脏读，就可以读到其他事务加了写锁的数据修改。

  若事务 1 对数据对象 A 加上 X 锁，事务 1 可以读 A 也可以修改 A，**其他事务不能再对 A 加任何锁**，直到事物 1 释放 A 上的锁。这保证了其他事务在事物 1 释放 A 上的锁之前不能再读取和修改 A（但是可以快照读）。**排它锁会阻塞所有的排它锁和共享锁。**

## MySQL中的表锁有哪些？

MySQL 里表级锁有两种：**表锁、元数据锁，**还有轻量级的**AUTO-INC锁**（自增锁）。

**表锁**

对于表锁，分为两类：

- 表共享读锁（read lock）
- 表独占写锁（write lock）

表锁的语法是：

```sql
LOCK TABLES table_name [READ | WRITE]
```

可以用 `unlock tables` 主动释放锁，也可以在**客户端断开**的时候自动释放。lock tables 语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。

对于 InnoDB 这种支持行锁的引擎，一般不使用 lock tables 命令来控制并发，毕竟锁住整个表的影响面还是太大。

**元数据锁（meta data lock）**

简称 MDL

- MDL不需要显式使用，在访问一个表的时候会被**自动加上**。

- MDL 的作用：**保证读写的正确性。**


在对一个表做增删改查操作的时候，自动加 MDL 读锁；当要对表做结构变更操作的时候，自动加 MDL 写锁。

读锁之间不互斥，读写锁之间，写锁之间是互斥的，用来保证变更表结构操作的安全性。

**AUTO-INC锁**

也就是在**执行插入语句时**（带有 `AUTO_INCREMENT` 列）就在表级别加一个AUTO-INC锁，然后为每条待插入记录的含有AUTO_INCREMENT修饰的列分配递增的值。

## InnoDB引擎的行锁是怎么实现的？

InnoDB是**基于索引**来完成行锁，在锁的算法实现上有三种：

- Record lock：记录锁，单个行记录上的锁，简称行锁。

- Gap lock：间隙锁，锁定一个范围，**不包括记录本身**，是开区间。

- Next-key lock：临键锁，是record+gap的组合，锁定一个范围，包含记录本身。是左开右闭的区间。


Gap锁设计的目的是为了阻止**多个事务**将记录插入到同一范围内，而这会导致**幻读**问题的产生。

**innodb对于行的查询使用next-key lock锁**，Next-locking keying是Record lock和Gap lock的组合。当查询的索引**含有唯一属性**时，将next-key lock**降级**为record key。

有两种方式显式关闭gap锁：

- 第一种，将事务**隔离级别设置为RC；**
- 第二种，将参数innodb_locks_unsafe_for_binlog设置为1。

> 这里对 **记录锁**、**间隙锁**、**临键锁** 做一个总结：
>
> - **InnoDB** 中的**行锁**的实现依赖于**索引**，一旦某个加锁操作没有使用到索引，那么该锁就会退化为`表锁`。
> - **记录锁**存在于包括**主键索引**在内的**唯一索引**中，锁定单条索引记录。
> - **间隙锁**存在于**非唯一索引**中，锁定**开区间**范围内的一段间隔，它是基于**临键锁**实现的。
> - **临键锁**存在于**非唯一索引**中，该类型的每条记录的索引上都存在这种锁，它是一种特殊的**间隙锁**，锁定一段**左开右闭**的索引区间。

## 谈一下MySQL中的死锁

死锁是指**两个或两个以上的进程**在执行过程中，因**争夺资源**而造成的一种**互相等待**的现象，若无外力作用，它们都将无法推进下去。此时称系统处于死锁状态或系统产生了死锁。

**如何查看死锁？**

- 使用命令 `show engine innodb status` 查看最近的一次死锁。


- innodb锁监控-InnoDB Lock Monitor，每 15s 输出一次日志。**使用完毕后建议关闭**，否则会影响数据库性能。

  开启InnoDB Lock Monitor：默认是关闭的。

  ```sql
  SET GLOBAL innodb_status_output_locks=ON; 
  ```

**对待死锁常见的两种策略：**

- 通过 innodblockwait_timeout 来设置**超时时间**，一直等待直到超时；


- 发起**死锁检测**，发现死锁之后，主动回滚死锁中的某一个事务，让其它事务继续执行。


## 简述下MySQL8中的新增特性有哪些

MySQL8在功能上的我们需要关注增强主要有：①账户与安全；②索引增强；③InnoDB 增强等。主要表现在：

1. **账户与安全：**①用户的**创建与授权**需要两条单独的SQL语句执行；②认证插件更新；③密码管理和角色管理发生变化。
2. **索引增强：**

   1. **隐藏索引：**被隐藏的索引不会被优化器使用，但依然真实存在，主要用于**软删除**，可以根据需要后续真正删除或者重新可视化。

   2. **降序索引：**开始真正支持降序索引，以往的MySQL虽然支持降序索引，但是写盘的时候依然是升序保存。MySQL8.0中则是真正的按降序保存。另外新特性里面不再对group by操作进行隐式排序。

   3. **函数索引：**索引中可以使用**函数表达式**。在创建表时创建一个函数索引，**查询的时候使用同样的函数**就可以利用索引了。

3. **原子DDL操作：**MySQL 5.7执行drop命令 `drop table t1,t2;` 如果t1存在，t2不存在，会提示t2表不存在，但是t1表仍然会被删除。MySQL8.0执行同样的drop命令，会提示t2表不存在，而且t1表不会被删除，保证了原子性。

4. **自增列持久化：**解决了之前的版本，**主键重复**的问题。

   MySQL5.7及其以前的版本，MySQL服务器重启，会重新扫描表的主键最大值，如果之前已经删除过主键id=100的数据，但是表中当前记录的最大值如果是99，那么经过扫描，下一条记录的id是100，而不是101。

   MySQL8.0则是每次在变化的时候，都会将**自增计数器的最大值写入redo log**，同时在**每次的检查点将其写入引擎私有的系统表。**如此就不会出现自增主键重复的问题。
