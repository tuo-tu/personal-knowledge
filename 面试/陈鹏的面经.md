## 陈鹏的面经

### 6.25-沥泉科技

#### redis的四种限流算法？令牌桶算法如何实现？如何定时生成令牌？

固定窗口算法、滑动窗口算法、漏桶算法、令牌桶算法。令牌桶算法的特点是需要按一定的速率生成令牌，在go中可以使用 `golang.org/x/time/rate` 包来生成。

优缺点：

#### 讲一下MySQL的MVCC机制？

MVCC是指MySQL的多版本并发控制机制，它通过**为每条记录保留多个版本**，从而能够在**不加锁的情况下**实现数据库的并发读写。其主要内容包括**版本链和读视图。**

**版本链：**包括一个隐藏的row_id、隐藏的trx_id、指向旧版本记录的roll_pointer，不同的版本之间的数据通过回滚指针相连就形成了一个版本链。

**读视图：**read view，也称为一致性视图，维护一个活跃的事务列表，里面共包含4个关键字段：最小、最大、活跃事务列表、当前事务id。事务的隔离级别不同（特指RC、RR），生成视图的时机也不同。只有在**读已提交**和**可重复读**的隔离级别之下，MVCC才生效。

- 读已提交：每次执行SELECT都创建新的ReadView，能看到其他事务**最新已提交**的修改。
- 可重复读：只在第一次执行SELECT时创建ReadView，后续复用。

行数据的trx_id需要和一致性视图中的活跃事务列表作比较，来决定该版本是否可见。牢记：trx_id在其中是不可见的。小于时可见。通过隔离级别+可见性判断，就实现了MySQL多版本并发控制机制。

#### 主从复制？

全量复制

增量复制

#### 讲一下redis的集群模式？

集群模式是redis的一个重要的分布式部署方案，主要包括三个方面的内容：**数据分片、节点通信、故障转移**。故障转移也就是它的高可用机制。

1. redis的数据分片使用虚拟槽分区，使用一个哈希函数将所有的键映射到0 ~16383虚拟槽里面。

2. redis集群的节点间通信采用的是gossip协议进行通信。
3. 故障转移和哨兵机制类似，都要经过主观下线、客观下线、投票选举过程。

#### 讲一下redis的哨兵机制？

哨兵机制同样也是redis的高可用机制，它**通过部署哨兵节点**，来对整个主从架构进行监控。哨兵机制包括3个主要内容，分别是：**定时监控、节点下线、故障转移。**

1. 定时监控有3个任务，分别是每隔10秒、每隔2秒、每隔1秒。
2. 节点下线分为主观下线和客观下线，
3. 关于故障转移，首先会选出一个**领导者哨兵**来负责这个转移的工作。这个领导者会从下线的主节点的从节点当中选出一个作为新的主节点。

#### 开goroutine可以实现高并发，但是goroutine太多会产生巨大的成本，怎么解决？

重点在于**控制并发数量。**

1. 使用协程池，例如ants库
2. 使用缓冲channel和sync.WaitGroup

#### 既然是个人项目，如何经得起生产环境的检验？

个人项目重在学习技能，而不是解决现实问题。

#### IM实时通信系统中，用户的过期下线机制可以使用定时器timer，但是timer会产生大量的资源消耗，有其他实现方式吗？

以下方式可以尝试：

**1、时间轮（Time Wheel）算法**

- 用一个环形数组来代替大量定时器，把超时任务按“槽位”放入，统一定期扫描，效率为 O(1)。
- 每个用户连接都注册在时间轮中，**收到心跳时重置位置**，刷新一下，如果到期了就执行下线逻辑。
- Go 推荐使用：[`github.com/RussellLuo/timingwheel`](https://github.com/RussellLuo/timingwheel)

**2、使用小根堆**

- 使用 **小根堆** 保存所有用户的过期时间，堆顶就是**最早即将过期的用户**
- 开启一个goroutine循环等待堆顶用户的过期时间点，一旦超时就触发“下线操作”
- 用户活跃时，如收到心跳时，需要更新其过期时间（重新入堆，使用heap.Fix()）

#### websocket连接时如何携带消息数据的？

websocket是以**数据帧**的格式来发送数据，用户自己的数据会被存放在Payload里面。

还有一个关键点是opcode，表示消息类型。

加深。。。

#### 在一个商城项目里面如何实现商品状态的自动改变？

可以使用**状态机**来实现，golang中使用looplab/fsm包来实现。

1. 定义商品结构体，包括状态机成员
2. 初始化商品信息和状态机，包括商品初始状态、状态事件的定义
3. 完成状态迁移回调函数，即**状态变更时自动执行的回调函数**。

调用示例：

```go
package main

import (
	"fmt"
	"github.com/looplab/fsm"
)

type Product struct {
	ID    int
	State string
	FSM   *fsm.FSM
}

func NewProduct(id int) *Product {
	p := &Product{
		ID:    id,
		State: "draft",
	}

	p.FSM = fsm.NewFSM(
		p.State,
		fsm.Events{
			{Name: "approve", Src: []string{"draft"}, Dst: "active"},
			{Name: "reject", Src: []string{"draft"}, Dst: "rejected"},
			{Name: "expire", Src: []string{"active"}, Dst: "inactive"},
			{Name: "sellout", Src: []string{"active"}, Dst: "sold_out"},
			{Name: "freeze", Src: []string{"active"}, Dst: "frozen"},
			{Name: "relist", Src: []string{"inactive"}, Dst: "active"},
		},
		fsm.Callbacks{
			"enter_state": func(e *fsm.Event) {
				fmt.Printf("Product %d transitioned from %s to %s\n", p.ID, e.Src, e.Dst)
				p.State = e.Dst
			},
		},
	)

	return p
}

func main() {
	p := NewProduct(1001)

	_ = p.FSM.Event("approve")  // draft -> active
	_ = p.FSM.Event("sellout")  // active -> sold_out

	// 状态非法操作
	err := p.FSM.Event("relist") // sold_out -> active（不允许）
	if err != nil {
		fmt.Println("Illegal transition:", err)
	}
}
```

输出结果：

```css
Product 1001 transitioned from draft to active
Product 1001 transitioned from active to sold_out
Illegal transition: event relist inappropriate in current state "sold_out"
```

回调的命名必须遵循以下规则：

| 回调名称       | 触发时机               | 格式             | 说明                              |
| -------------- | ---------------------- | ---------------- | --------------------------------- |
| `before_EVENT` | 某事件被触发前         | `before_approve` | 在调用 `.Event("approve")` 前触发 |
| `after_EVENT`  | 某事件执行完状态切换后 | `after_approve`  | 适合做日志、通知等                |
| `leave_STATE`  | 离开某个状态之前       | `leave_draft`    | 可以检查是否允许离开此状态        |
| `enter_STATE`  | 进入某个状态之后       | `enter_active`   | 最常用，更新状态、写库、通知等    |
| `before_event` | 任意事件触发前         | 通用             | 日志/统一校验等                   |
| `after_event`  | 任意事件触发后         | 通用             | 日志/通知等                       |
| `leave_state`  | 离开任意状态之前       | 通用             |                                   |
| `enter_state`  | 进入任意状态之后       | 通用             |                                   |

> 🚨 注意：
>
> - `EVENT` 是事件名，`STATE` 是状态名，必须是在 `fsm.Events` 中定义过的！
> - 大写的EVENT表示指定事件，小写的event表示任意事件。

#### 在IM实时通信系统中，聊天双方的消息如何存储？

应该是Kafka+mongoDB。。。

在本项目中是存储在redis里面，然后根据自己需要再做持久化，可以根据消息类型，将一部分信息存储在MySQL中。实际上还有很多设计方式。比如

1. 在线消息：使用redis的zset结构来存储，主要是为了契合最近会话列表功能，然后异步存入MySQL中，异步写入。
2. 离线消息：使用redis的stream结构来存储，也会写入到MySQL当中。（当接收方不在线时，临时存储在redis中，并**设置过期时间**(?)。同时会写入 MySQL，但是需要将消息**标记为“未投递”状态**；用户上线后再获取离线的消息，然后**更新消息状态为“已投递”**。）
3. 历史消息是用来**稳定查询**的，都在MySQL里面，没有存储一说。
4. 心跳消息：不存储，但是可以记录最后一次心跳时间用于判断登录状态。

> redis存储**离线消息**，主要考虑到消息的队列特性，因此最好采用stream结构来存储。当然也可以使用list，但是不支持分组消费。
>
> 如果在线会话消息也使用redis来存储，那最好采用zset来存储，因为zset有排序和去重的特性，能很好满足比如微信的最近会话列表功能。

**离线消息** 是：**"你离线时别人发给你的消息"（未投递过）**
**历史消息** 是：**"你查聊天记录时看到的所有消息（已读或未读）"**

#### redis的主从复制中，如何保证从节点复制的数据不丢失？

详见redis文档，有全量同步，部分同步。

1. 在全量同步里面，主节点会将在RDB传输期间的写操作记录下来，然后再发送给从节点。
2. 在增量复制阶段，采用的是**复制命令**的方式。并且如果从节点断开了，主节点还可以将命令存放在复制积压缓冲区中，在从节点上线后，主节点根据从节点的请求再发送过去。

**有重定向机制。。。。**

### 7.13-信工所

#### 是否可接受多语言C++、python等进行编程？

可以接受

#### 对于加班怎么看？

按照项目的进度进行的加班，完全可以接受。

#### 讲一下你对MySQL的索引的理解？



MySQL中索引包括**B+树索引、全文索引、哈希索引**等，其中最重要的是B+树索引。在B+树里面呢，**只有叶子节点存放具体的数据**，非叶子节点存放键值和指向叶子节点的指针。

B+树索引可分为聚集索引、二级索引。

聚集索引的叶子节点存放了完整的数据记录，二级索引的叶子节点存放的是**索引列的值和聚集索引的值**，当使用到某个二级索引但是不能进行**索引覆盖**的话，就会通过聚集索引做一次回表操作来获取完整的数据纪录。

#### 讲一下MySQL中事物的隔离级别？

MySQL中事物的隔离级别有4个，由低到高依次是读未提交、读已提交、可重复读、可串行化。

**读未提交：**指的是一个事务可以看到其他事务尚未提交的数据，会发生脏读。

**读已提交：**指的是一个事务只能读取到其他事务已经提交的数据，会发生不可重复读。

**可重复读：**指的是一个事务多次读取同一条数据，结果是一样的，避免了脏读和不可重复读。

**可串行化：**指的是所有的事务都串行执行

#### C++中的指针和go中的指针的区别？

C++中的指针可以做指针运算，需要进行手动内存管理；

**Go中的指针不可以做指针运算，支持自动的垃圾回收。**

#### 讲一下Go中的错误处理机制？

在Go语言中，错误处理是通过`error`接口实现。`error`接口定义了一个`Error()`方法，用于返回错误的**字符串描述**。在实际的操作中，主要通过**多返回值**和**明确的错误检查**实现。

另外，Go中还有一种特殊的方式，就是在defer语句中使用`recover()`来捕获panic，让程序继续可以执行下去。

### 7.15-愿景互娱

#### 事物的4个特性？

ACID，原子性、隔离性、一致性、持久性

#### TLS协议了解吗？

TLS 是传输层安全协议，用于保障网络通信的加密特性，与加上http协议就变成了https。

#### 讲一下正向代理和反向代理？

正向代理是代理客户端，隐藏了客户端的IP，反向代理是代理服务器，隐藏了服务器的地址。

#### Golang中的原子操作和锁？

原子操作使用atomic，锁有共享锁、排他锁。

#### MySQL中共享锁和排他锁的实现方式？

共享锁使用 LOCK IN SHARE MODE

排他锁使用 FOR UPDATE

#### 旧版本的浏览器无法使用websocket协议，那它是使用什么方式进行双向通信呢？

1. 轮询（Polling）

   客户端**定时**发送 AJAX 请求，向服务器询问“有没有新消息”。

2. 长轮询

   客户端发出请求后，服务器如果没有新消息，会**挂起请求（阻塞）**，直到有新消息才响应。

#### 项目的微服务中使用的通信方式？

gRPC

#### 微服务之间如何调用？有服务宕掉怎么办？

使用consul作为服务注册发现中心。consul有健康检查机制，可以判断服务是否处于“正常运行状态”。

#### 讲一下常见的负载均衡算法？

轮询（Round Robin）、加权轮询（Weighted RR）、随机（Random）等算法。

#### Jaeger链路追踪如何实现？

初始化一个全局的追踪器tracer（需给追踪器取个名字，其中会配置采集策略），通过tracer.Start(r.Context(), "handle-request")启动采集；

Gin 框架中集成 Jaeger是使用中间件。

#### 微服务对比单体架构的优劣？

**优势：低耦合度**

1. 每个服务可以独立开发部署，互不干扰

2. 可扩展性更好

3. 维护起来更方柏霓

**劣势：**

1. 架构复杂度高，涉及服务的注册、发现、通信、熔断等等；
2. 部署运维成本高
3. 必然导致分布式架构涉及的一些问题，如服务调用失败、网络延迟等等

#### redis中如何实现原子操作？

- pipeline（流水线）：go中使用pipe.Exec(ctx)执行
- 分布式事务：muilt开始，exec执行，discard类似于回滚，还可以使用watch命令进行监控。
- Lua脚本：主要使用eval和evalsha命令（要先通过script生成一个摘要）

#### 排行榜系统使用什么数据结构来存储？它的底层实现？

使用Zset结构。Zset的底层实现由**压缩列表和跳表。**

- 元素数量小于128个且所有元素的长度都小于64字节使用压缩列表。
- 其他情况使用跳表。

解释： 跳表在范围查询时效率高。

#### 讲一下go中的goroutine？看后面

1. goroutine是go中的用户级线程，是执行并发任务的基本单元。
2. 使用go关键字进行启动。
3. goroutine的调度模型是GMP，包括**协作式**和**抢占式**调度。

### 7.15-为基信息

#### redis的持久化机制？具体的机制说明，优劣比较等？

redis有2种持久化机制，分别是RDB、AOF。其中RDB是默认开启的持久化机制。

**RDB方式**

RDB是通过**全量快照**的方式来进行持久化。

生成快照的方式包括**手动触发**和**自动触发**两种方式。

- 手动触发包括save和bgsave两个命令，前者会阻塞主线程，后者不会，是默认配置。

- 自动触发是通过配置

RDB持久化的优点是**加载速度极快**，缺点是无法做实时持久化，会丢失秒级的数据。

**AOF方式**

AOF是通过命令追加的方式来进行持久化。

也就是说操作命令会被写到一个独立的日志文件里面，可以通过配置文件同步策略来控制写回的频率。

AOF日志文件生成有3种策略：always、everysec、no

随着日志文件越来越大，就会触发命令重写机制，把多个命令压缩成一条等效命令，来减小文件的体积。

AOF的重写机制同样包括**手动触发**和**自动触发**两种方式。

- 手动执行通过`bgrewriteaof`命令，会fork出一个子进程来完成。
- 自动触发时需要配置。

AOF持久化的优点是**数据比较安全/完整**，缺点就是**恢复速度慢**，特别是命令比较多得时候。

#### golang的过期机制？

使用定时器Timer、context、时间轮、小根堆等；

#### golang的优雅退出机制？

sysn.waitgroup()、`os/signal` 包

#### MySQL的执行计划的重要指标？

主要看type字段（包含好几种级别：system > const > eq_ref > ref> range > index > ALL）、

key、rows、Extra（例如使用了**覆盖索引**Using index）

#### http的状态码？头信息？

👉 状态码分类：

| 分类 | 含义                         | 示例                                  |
| ---- | ---------------------------- | ------------------------------------- |
| 1xx  | 信息，表示请求已接收         | `100 Continue`                        |
| 2xx  | 成功，表示请求已成功处理     | `200 OK` / `204 No Content`           |
| 3xx  | 重定向，需要客户端进一步操作 | `301 Moved Permanently` / `302 Found` |
| 4xx  | 客户端错误                   | `400 Bad Request` / `404 Not Found`   |
| 5xx  | 服务器错误                   | `500 Internal Server Error`           |

✅ 常见状态码详解：

| 状态码                      | 含义                 | 典型用途                        |
| --------------------------- | -------------------- | ------------------------------- |
| `200 OK`                    | 请求成功             | 常见于 GET、POST 响应           |
| `201 Created`               | 成功创建资源         | POST 创建成功时返回             |
| `204 No Content`            | 请求成功但无响应体   | DELETE、PUT 返回                |
| `301 Moved Permanently`     | **永久重定向**       | SEO 优化，变更 URL              |
| `302 Found`                 | **临时重定向**       | 登录跳转                        |
| `304 Not Modified`          | 缓存未更新           | 浏览器缓存控制                  |
| `400 Bad Request`           | 客户端请求错误       | 参数缺失、格式错误              |
| `401 Unauthorized`          | 未认证               | Token 失效                      |
| `403 Forbidden`             | 没有权限             | 非授权访问                      |
| `404 Not Found`             | **资源不存在**       | 常见错误页                      |
| `405 Method Not Allowed`    | **请求方法不被允许** | 比如 GET 请求了只能 POST 的接口 |
| `500 Internal Server Error` | 服务端异常           | panic、bug                      |
| `502 Bad Gateway`           | **网关错误**         | Nginx → 后端超时                |
| `503 Service Unavailable`   | 服务不可用           | 服务器过载、维护中              |
| `504 Gateway Timeout`       | 网关超时             | 后端服务超时                    |

✅ 常见请求头（Request Header）

| 请求头            | 作用                                    |
| ----------------- | --------------------------------------- |
| `Host`            | 请求的主机名                            |
| `User-Agent`      | 客户端设备类型、浏览器等                |
| `Accept`          | 客户端希望接收的数据类型                |
| `Content-Type`    | 请求体的数据格式，如 `application/json` |
| `Authorization`   | 身份认证（如 `Bearer <token>`）         |
| `Cookie`          | 携带会话、身份信息                      |
| `Referer`         | 请求来源页面                            |
| `Origin`          | 发起请求的源，用于跨域判断              |
| `X-Forwarded-For` | 获取真实 IP 地址（反向代理）            |

✅ 常见响应头（Response Header）

| 响应头                        | 作用                                   |
| ----------------------------- | -------------------------------------- |
| `Content-Type`                | 响应体的数据格式                       |
| `Set-Cookie`                  | 设置 cookie                            |
| `Cache-Control`               | 缓存策略，如 `no-cache`, `max-age`     |
| `Content-Length`              | 响应体大小                             |
| `Location`                    | 重定向地址（用于 301/302）             |
| `Access-Control-Allow-Origin` | CORS 跨域控制                          |
| `ETag`                        | 缓存验证字段                           |
| `Server`                      | 服务端软件标识，如 `nginx/1.20`        |
| `Connection`                  | 控制连接类型，如 `keep-alive`、`close` |

#### 在Golang中，死锁如何检测、避免？

产生：两个或多个 goroutine **互相等待对方释放资源**。

检测：

1. 命令行会报错：`fatal error: all goroutines are asleep - deadlock!`
2. 使用pprof工具，打开网页，查看goroutine相关信息，看到**deadlock关键字**就说明有死锁。

避免：

1. 始终保持**锁获取的顺序一致**
2. 尽量缩小**锁的持有时间**
3. 使用channel作为通信手段
4. 可以在使用锁之前使用trylock尝试加锁

#### Goroutine（协程）的安全问题有哪些机制来保障？

锁、原子操作、channel、context、信号量等

#### 讲一下JWT的优缺点？

优点：无状态性，服务端不用保存token的信息。

缺点：签发的Token无法主动过期。

#### 讲一下pprof？

`pprof` 是 Go 提供的一种 **性能剖析工具**，用于分析程序的运行时行为。比如查看CPU的耗时情况、内存堆栈分析、goroutine等。

#### Golang和其他语言相比的优势？

1. 语法简洁
2. 并发操作比较简单
3. 单个goroutine的资源消耗少

#### Protobuf 和json进行服务间通信的优劣比较？

Protobuf是二进制编码，**体积小**，有专门的语法。

但是json的可读性强，不需要进行额外的解析。但是体积大；

#### Json的序列化和反序列化注意事项？tag标签的重要字段（omiempty）？

1. 成员字段必须大写开头
2. 可以使用`omitempty` 控制非必须的字段，减少传输数据
3. 用 `json:"-"` 忽略敏感/内部字段

#### 如何在docker上部署自己的项目？

1. 第一步：准备好Go目录文件，执行 go build；

2. 第二步：编写 Dockerfile（多阶段构建）

   ```dockerfile
   # 第一阶段：构建阶段
   FROM golang:1.21 AS builder
   
   WORKDIR /app
   
   COPY go.mod go.sum ./
   RUN go mod download
   
   COPY . .
   
   RUN go build -o myapp
   
   # 第二阶段：运行阶段
   FROM alpine:latest
   
   # 安装证书以支持 HTTPS
   RUN apk --no-cache add ca-certificates
   
   WORKDIR /root/
   
   # 从 builder 阶段复制二进制
   COPY --from=builder /app/myapp .
   
   # 启动程序
   CMD ["./myapp"]
   ```

3. 第三步：创建 `.dockerignore`

4. 第四步：构建 Docker 镜像

   打开终端，进入项目目录，执行命令：

   ```bash
   docker build -t myapp:latest .
   ```

   解释：

   - `myapp`：镜像名称
   - `latest`：标签，可自定义为 `v1.0.0` 等

5. 第五步：运行容器

6. 第六步：查看容器状态与日志

总结：

```
1. 编写代码 (main.go)
        ↓
2. 创建 Dockerfile 和 .dockerignore
        ↓
3. docker build -t myapp .
        ↓
4. docker run -d -p 8080:8080 myapp
        ↓
5. 查看结果（浏览器或 curl）
```

#### Docker中的文件目录映射

也被称为持久化，两种方式

1. 使用Volume（数据卷）：-v或者--mount
2. 使用Bind Mount（绑定挂载）

二者区别在于Bind Mount可以**手动指定宿主机的路径。**

| 特性/区别项         | **Bind Mount**                          | **Docker Volume**                             |
| ------------------- | --------------------------------------- | --------------------------------------------- |
| **创建方式**        | **手动指定宿主机路径**                  | 通过 Docker 自动管理，`docker volume` 命令    |
| **挂载位置**        | 宿主机上的任意路径（必须是绝对路径）    | Docker 自有路径：如 `/var/lib/docker/volumes` |
| **可挂载内容**      | 文件或目录                              | 只能挂目录                                    |
| **是否可只读挂载**  | ✅ 支持 `:ro`                            | ✅ 支持 `:ro`                                  |
| **使用方式**        | `-v /path:/path` 或 `--mount type=bind` | `-v 卷名:/path` 或 `--mount type=volume`      |
| **可移植性**        | ❌ 差：依赖宿主机路径结构                | ✅ 高：与宿主无关，适合备份/迁移               |
| **适合场景**        | 本地开发、调试配置文件                  | 持久化数据、容器数据共享                      |
| **Docker 管理能力** | ❌ 无法用 Docker 命令统一管理            | ✅ 可用 `docker volume` 命令进行管理           |
| **备份/恢复**       | ❌ 不便                                  | ✅ 易于使用 `docker volume export/import`      |
| **性能优化**        | ❌ 无 Docker 的文件系统优化              | ✅ 自动优化，尤其是 Linux 上的 volume          |
| **安全性**          | ❌ 不隔离，宿主文件系统暴露              | ✅ 更隔离，推荐生产使用                        |

#### 讲一下kratos框架的优势？

1. 脚手架能够快速启动项目
2. 有清晰的分层架构

#### golang的高并发如何实现？了解过其他语言如何实现吗？

Golang 的高并发主要依赖 goroutine 和 channel，运行时通过GMP调度模型把海量协程映射到少量 OS 线程上。

#### 讲一下代理和反向代理？

正向代理是代理客户端，反向代理是代理服务器。

### 7.25-诺云网络

#### Redis有哪些业务场景？

1. **缓存热点数据**

   - 高频访问但更新不频繁的数据放到 Redis，减少数据库压力。
   - 例子：用户信息、商品详情页数据、热门文章等。

2. **计数器**

   - Redis 原子操作适合计数，支持高并发场景。
   - 例子：**点赞数、浏览量**。

3. **限流**：接口访问限流（滑动窗口、漏桶算法、令牌桶等）。

4. **轻量级消息队列**
   - 使用 Redis List、Stream 作为**轻量级消息队列。**
   - 例子：异步任务处理、消息通知。

5. **消息发布订阅：**发布订阅模式（Pub/Sub）可做通知广播。

6. **会话管理**：比如Token存储等；

   - 存储用户的登录状态、验证码、Token、Session，设置过期时间实现自动过期。
   - 例子：单点登录、分布式系统下的用户认证。

7. **分布式锁**

   - 利用 SETNX / RedLock 实现分布式锁：分布式环境下保证任务只执行一次。

     示例：秒杀、抢购业务；

8. **排行榜/计分系统**
   - 利用 `ZSet` 实现实时排行榜。
   - 例子：游戏积分榜、热搜榜。

9. **地理位置服务 (GIS)**
   - Redis 的 Geo 类型可以做附近的人、附近的店。
   - 例子：打车软件的司机定位、外卖商家推荐。

#### IM实时通讯系统中，如果消息量特别大，该怎么处理？

mongoDB存储

这个问题太大了。

✅ 1. **接入层扩展（水平扩容）**

- **多节点部署 + 负载均衡**：IM 服务前面加 Nginx / LVS / 四层负载均衡，使用 **一致性哈希** 保证用户连接尽量落在固定节点。
- **连接层水平扩展**：WebSocket/长连接由多个节点分担，避免单点瓶颈。

------

✅ 2. **消息存储 & 转发**

- **异步化**：消息写入队列（Kafka / RabbitMQ / Redis Stream），由消费端异步分发，降低直接写数据库的压力。
- **削峰填谷**：队列能缓冲高峰期流量，避免数据库崩溃。
- **分布式存储**：消息落库时采用分库分表（如按用户 ID hash）。

------

✅ 3. **消息投递优化**

- **点对点消息**：利用 Redis Pub/Sub 或 Kafka Topic，按用户 ID/群 ID 进行分发。
- **群聊消息**：只存一份消息，消费端做 **多播**，减少重复写入。
- **在线/离线分流**：
  - 在线用户走内存/缓存快速推送。
  - 离线用户消息写入数据库或 Redis，等用户上线时再拉取。

------

✅ 4. **数据库 & 缓存优化**

- **冷热数据分离**：
  - 热数据（最近消息）放 Redis，快速访问。
  - 冷数据（历史消息）落 MySQL/ES。
- **批量写入**：把多条消息批量插入数据库，减少 IO 次数。

------

✅ 5. **其他优化手段**

- **消息顺序性**：同一会话消息通过 **同一分区/同一节点处理**，避免乱序。
- **限流 & 优先级队列**：限制恶意刷消息的用户，保证系统稳定性。
- **监控 & 自动扩容**：监控队列长度、消息堆积情况，触发自动扩容。

> 对于这种实时通讯类的消息，因为我们是做私域直播的，所以说直播间发言会很多，比如直播间有几千上万人，然后发言频率特别高的话。要怎么处理？或者说怎么设计？

**面试官回答：**限频 + 内容过滤（反垃圾/反灌水）

因为数据量大的话，你可能服务扩容它也能扩容，也不是就是最终目的，你一直扩的话，你机器那么多，可能成本也不够。所以说你可能需要结合业务场景，嗯类似一些这种纯数字的一些发言可能或者一些无效的发言，可能要就需要过滤掉。

✅ 1. **用户限频（Rate Limiting）**

- **单用户维度限流**
  - 每个用户在直播间里发言设置 **时间窗口**（比如 1 秒 1 条，5 秒 3 条）。
  - Redis + Lua 脚本实现原子计数（滑动窗口/漏桶/令牌桶算法）。
  - 超过阈值的消息直接拒绝，或者标记为低优先级丢弃。
- **房间维度限流**
  - 直播间整体消息速率过高时，系统会触发限流（比如 QPS 超过 5000/s 就启用“弹幕慢模式”）。
  - 普通用户消息不再即时广播，而是做合并/采样。

------

✅ 2. **内容过滤（Message Filtering）**

- **敏感词过滤**：对消息内容做关键词匹配（Trie 树 / DFA 算法 / Aho–Corasick 算法），命中即拒绝或替换。
- **无意义消息过滤**：
  - 重复内容（用户刷屏“哈哈哈哈”“1111”）直接丢弃。
  - 过短消息（仅表情、符号）可选择不广播。
- **风控策略**：如果某个用户持续触发违规（刷屏/敏感词），可以触发 **禁言 / 踢出房间**。

------

✅ 3. **系统层面的降级策略**

- **消息合并**：同一秒钟内的多条低价值消息，合并后一次性推送给客户端（例如“用户123发了10条哈哈” → “用户123: 哈哈×10”）。
- **采样推送**：当房间人数过多时，只广播部分普通用户消息（例如只展示最近 N 条，或者采样 30% 普通用户的发言）。
- **优先级投递**：主播/管理员/付费用户消息优先保证实时送达，普通用户消息可能被降级。

#### 你对Redis的队列了解哪些？

**1、List（最常见）**

- **实现方式**：`LPUSH` + `RPOP`（或 `RPUSH` + `LPOP`）。
- **特点**：天然支持队列结构，先进先出。
- **阻塞操作**：支持 `BLPOP/BRPOP`，消费者可以阻塞等待新消息。
- **不足**：
  - 不支持消费确认（ack），一旦被 pop 出来就没了，消费者挂了可能导致消息丢失。
  - 不支持多消费者消费同一条消息。

👉 适合 **简单任务队列**、**异步处理**。

------

**2、Pub/Sub**

- **实现方式**：生产者 `PUBLISH`，消费者 `SUBSCRIBE`。
- **特点**：发布订阅模型，消息即时推送到所有订阅者。
- **不足**：
  - **无持久化**，消费者没订阅或挂了，消息直接丢失。
  - 不支持消息堆积。

👉 适合 **实时通知、广播消息**，不适合做可靠队列。

------

**3、Stream（Redis 5.0 引入）**

- **实现方式**：`XADD`（写入）、`XREAD`（读取）、`XREADGROUP`（消费组）。
- **特点**：
  - 类似 Kafka，支持 **消费组**（一个消息可被多个组消费，组内消费者分摊消息）。
  - 支持 **ack 确认机制**（`XACK`），保证消息至少被消费一次。
  - 支持消息持久化（保留历史消息）。
- **不足**：
  - 消息积压过多时，内存压力大。
  - 功能比 Kafka 弱一些，没有复杂的分区/副本机制。

👉 适合 **需要可靠投递的队列**，比如订单、IM 消息。

#### list作为队列只能一个一个弹出，消费比较慢，如何解决这个问题？

1. 新版的redis的`LPOP`/`RPOP`的命令支持**批量弹出。**
2. 结合Lua脚本，可以实现批量弹出。

#### 你平常是怎么做MySQL的优化的，结合你自己的平时的业务讲讲？

SQL优化的核心思路是**减少扫描的行数、提高索引的利用率、降低磁盘 I/O**。可以结合explain执行计划来分析SQL语句。我平常做SQL优化有以下的经验：

1. 减少 `select *` 的使用；

2. 为所需字段**建立合适的索引**，主要就是联合索引了；

3. 联合索引要满足**最左前缀原则**；

4. 尽量满足**覆盖索引**，不用回表；

5. 尽量不要在大字段（比如字符串是可以非常长的列）上建立索引。

   > 因为页的大小是16KB，存大字段很快就被塞满，就会发生回表。如果缓存中没有还会发生磁盘I/O。

####  LIMIT offset, count; 这种语句，offset 越大，分页越慢，查询的时间越长，有什么优化方案？

比如：

```sql
-- OFFSET 写法（慢）
SELECT * FROM user ORDER BY id LIMIT 1000000, 20;
```

**优化1：**使用**上次分页的最大id**（效果最好，推荐使用），也叫**游标分页。**

如果id是主键，那么直接使用：

```sql
-- 假设上一页最后一条记录的id是 1000000
SELECT * 
FROM user 
WHERE id > 1000000  -- 直接定位到偏移量位置
ORDER BY id 
LIMIT 20;
```

👉 优点：性能稳定，不管是第 1 页还是第 10000 页，速度都差不多。
👉 缺点：只能顺序翻页，不能直接跳到第 N 页。

**优化2：**使用**子查询覆盖索引**。

```sql
select * 
from user 
where id > (
    select id 
    from user 
    limit 1000000,1
) 
limit 20;
```

**优化3：延迟关联（Late Join）。**

避免在大表上直接做 `OFFSET`。子查询先查询id。

```sql
SELECT u.* 
FROM user u
JOIN (
    SELECT id FROM user ORDER BY id LIMIT 1000000, 20
) t ON u.id = t.id;
```

👉 优点：先只查索引（轻量），再回表获取数据。
👉 缺点：依然要扫描 offset，但比直接查全表字段快。

#### 讲一下map的底层结构或实现机制？

map的底层是就是hash表，具体来说它是一个hmap的数据结构，底层结构有两个关键的地方，**桶和溢出桶。**

1. 两种桶都可以用来存放键值对，默认可存储 **8 个键值对**。
2. 溢出桶主要是用来解决哈希冲突的。

map是以空间换时间的典型案例。

#### 你的滴滴代驾、购物商城项目，微服务是按照什么原则去拆分的？

**1、按照单一职责原则（SRP）**

- 每个服务只负责一个相对独立的业务领域，不要大而全。
- 例如在电商系统里：订单服务只管订单，库存服务只管库存。

**2、按业务领域划分（DDD 思想）**

- 参考领域驱动设计，把复杂系统按 **领域** 划分成子域。
- 电商系统可拆成：用户域、商品域、交易域、支付域等。

在“滴滴代驾”项目里，服务拆分遵循了**单一职责和领域驱动设计**原则，比如验证码、费用预估属于单一职责，顾客、司机属于领域划分。
在“购物商城”项目里，服务拆分主要遵循**领域驱动设计**。比如用户、商品、购物车、订单、支付等服务分别对应不同的业务领域。

#### 讲一下你用到的 git工作流（模型）？

git的工作流主要有**Git Flow**（比较经典的工作流）、**GitHub Flow**（轻量化工作流）。

**1、Git Flow**（比较经典的工作流）

- 分支角色：
  - `master`：线上稳定分支
  - `develop`：日常开发主分支
  - `feature/*`：开发新功能
  - `release/*`：预发布版本
  - `hotfix/*`：线上 bug 修复
- 优点：流程清晰，适合版本迭代、多人协作的场景。
- 缺点：分支多、比较重，比较复杂。

**2、GitHub Flow**（轻量化工作流）

- 主分支：`main/master` 永远可发布
- 开发者从 `main` 切出 `feature-branch`，开发完成后提 PR（Pull Request） 合并回 `main`。
- 优点：简单，分支少，适合快速迭代、持续部署。
- 缺点：不太适合版本管理复杂的大项目。

### 7.31-软牛科技

#### 讲一下你对Goroutine和channel的理解吧？

Goroutine 是 Go 语言中的用户级的**轻量级线程**，它是**执行并发任务的基本单元**。它也是Go语言实现高并发的基础，因为每个goroutine占用的内存很小，所以能够轻松创建成千上万个goroutine从而实现高并发。

Channel 可以理解为一个**线程安全**的队列，它用于在不同 Goroutine 之间传递数据，也称为协程通信工具。

#### 我现在初始化了一个int型的channel，缓冲为1。然后我往channel里面写了个100的数字。写完以后我close这个channel。之后我再从这个channel里面读两次值，能读得到值吗？或者说读到的是什么值？

第一次读：得到 `100`。

第二次读：得到 `0`值（`int` 类型的零值）。

**延申：**

channel **一旦关闭且缓冲区数据被读空后**，后续 **所有的读取** 都会：

- 返回 **类型的零值**（这里是 `0`），
- 并且 `ok = false`。

**所以：**

- 第一次读 → `100, true`
- 第二次读 → `0, false`
- 第三次读、第 N 次读 → 依然是 `0, false`

不会再有新数据出现，也不会阻塞。

------

如果**无缓冲 channel**：因为没有存储，**一旦关闭后所有读取都是零值并且 `ok = false`**，不会阻塞。

**再注意一点：**读关闭的 channel 永远不会报错，只是返回零值；**写关闭的 channel 一定 panic。**

#### 你在实际开发中有遇到过一些协程，或者一些并发的问题吗？

有的。

比如channel导致的泄漏，没有对应的消费者去读，就会造成 goroutine 卡住，最终资源泄露。

还有 map 并发处理问题，有时候就会忘记加锁。

#### goroutine如何优雅的关闭？

主要用sync.WaitGroup。还可以用context来延时关闭、或者channel来传递信号。

#### 你刚才也提到waitgroup, 那你讲一下sync并发包的一些常用的工具，还有你的理解吧？

sync包里面的内容包括 sync.atomic、sync.cond、sync.Map、sync.once、sync.pool（用于缓存临时对象）、sync.waitgroup等。

#### 讲一下进程、线程、协程之间的关系？

进程是操作系统**资源分配**的最小单位，线程是操作系统**调度**的最小单位，一个进程可以包含多个线程，线程之间共享进程资源，以上两个都是操作系统级别的。而协程是用户级的轻量级的线程，比线程还要轻量很多，初始栈只有2KB，协程的调度不依赖操作系统，但是协程最终要被绑定到线程上才能被真正执行。

#### 假如你的项目中有一些goroutine泄露，你有什么样的排查思路呢？

可以通过 `pprof` 的 `goroutine` profile性能分析，查看每个 `goroutine` 的当前状态（运行、阻塞、等待），以及它们的**调用堆栈**。如果发现有大量 `goroutine` 堆栈停留在某个特定函数（例如，一个 `select {}` 或一个未完成的 I/O 操作）并且数量持续增长，那很可能就是泄露点。

**解释：**

> **“通过 pprof 的 goroutine profile，你可以看到每个 goroutine 的当前状态（运行、阻塞、等待），以及它们的调用堆栈。”**

- pprof 的 goroutine profile（如 `http://localhost:6060/debug/pprof/goroutine?debug=2`）会把当前程序中**所有 goroutine**的栈信息 dump 出来。
- 每个 goroutine 会带一个状态标签（常见有 `running`、`runnable`、`syscall`/`IO wait`、`chan send`、`chan receive`、`semacquire`、`select`、`sleep` 等），以及该 goroutine 当前正在执行的**调用堆栈**（函数名 + 源文件:行号）。
- 这就意味着你能**看到哪个 goroutine 在哪里被阻塞、为什么被阻塞**（比如阻塞在 `chan send`、等待锁或等待 I/O）。

> **“如果发现有大量 goroutine 堆栈停留在某个特定函数……并且协程数量持续增长，那很可能就是泄露点。”**

- 如果你看到大量 goroutine 的**栈都几乎相同（相同的函数序列）**，说明很多 goroutine 都卡在同一个位置没有退出。
- 如果这个数量随时间持续增长（`runtime.NumGoroutine()` 上升且不回落），说明这些 goroutine 没被回收 —— 即**泄露**。
- 例如：大量 goroutine 都在 `somepkg.doWork()` 的 `select { case ch <- v: ... }` 或者 `for { select {} }` 上卡住，那 `doWork` 或其上层调用很可能存在设计缺陷（比如往没有消费者的 channel 写、没有 cancel 的 context、select 永远阻塞等）。

------

**调用堆栈：**可以把 **调用堆栈（Call Stack）** 理解为 **函数调用的轨迹**，但是它不仅仅是“当前函数的名字”，而是**一条从最顶层到当前位置的函数调用链**。

#### 讲一下MySQL的事务？

事务（Transaction）**是一组 **原子化的 SQL 操作，要么全部执行成功，要么全部失败回滚。事务有4大特性：原子性、隔离性、一致性、持久性。

#### 你是怎么理解的索引的？MySQL的索引都有哪些呢？

索引是一种数据结构，类似于书的目录，它是用来加快查询速度的。MySQL中的索引主要是指B+树索引。MySQL常见的索引有主键索引、唯一索引、普通索引、联合索引、前缀索引，这些都属于B+树索引。其他索引有hash索引、全文索引、空间索引等。

#### 那SQL优化有哪些方法？

SQL优化的核心思路是**减少扫描的行数、提高索引的利用率、降低磁盘 I/O**。可以通过explain执行计划来分析SQL语句。

> type 的主要类型及其含义
>
> 1. **system** 表中仅有一行数据，通常是系统表，查询速度极快。
> 2. **const** 表示通过主键或唯一索引进行等值查询，最多返回一行数据，性能非常高。
> 3. **eq_ref** 针对连接查询，被驱动表使用主键或唯一索引进行一对一匹配，效率较高。
> 4. **ref** 使用非唯一索引（普通索引）进行**等值查询**，可能返回多行数据。
> 5. **range** 使用**索引范围扫描**，适用于 BETWEEN*、*<*、*>等条件，性能优于全表扫描。
> 6. **index** 全索引扫描，遍历整个索引树，避免回表，但数据量大时性能较低。
> 7. **ALL** 全表扫描，未使用索引，性能最差。

SQL优化包括：

1. 减少select *的使用
2. 为所需字段**建立合适的索引**
3. 联合索引需满足**最左前缀原则**
4. 尽量满足**覆盖索引**，不用回表
5. 尽量不要在大字段上建立索引

等等方法。

#### 你的IM实时通信项目中，聊天消息的实时性和顺序性，是怎么保证的？

实时性通过 WebSocket 连接来保证，顺序性通过Redis的stream结构来保证。

Kafka顺序保证？

#### 那微服务的可用性设计怎么去保证呢？

服务注册与发现、负载均衡、熔断、降级、限流、分布式事务处理、监控、链路追踪。

### 7.31-NEC中国

#### 问题1

面试官：比如说我现在有一个枚举的类型，实际业务里面经常会有这种log的那种级别，比如说log里面比如说是警告啊，还是错误啊，还是什么的，是提示啊，这种各种不同的级别嘛，是吧？然后呢，然后后来我这个比如说我有一段进程，比如说我是用C语来写了一个定义，一个美举的型号，针对这个log级别的有一个定义，就是这种定义的话，如果用那个Golang来实现，它怎么样去定义？

> 使用**常量 + iota** 来实现枚举效果：
>
> ```go
> type LogLevel int
> const (
> 	LogInfo LogLevel = iota // 0
> 	LogWarning              // 1
> 	LogError                // 2
> 	LogDebug                // 3
> )
> ```

面试官：枚举类型比如我现在这边有8个值，我能取几个值啊？同时能从这个8个里面能取几个？

> 只能取一个

#### 问题2

下面的代码打印出什么

```go
arr := [...]string{"Apple", "Banana", "Orange", "Pear"}
arr1 := arr[1:3] // arr[1] arr[2] <=arr[3]
fmt.Println(arr1)
```

> 输出：[Banana Orange]

#### 问题3

下面的代码打印出什么？

```go
s := []string{"Apple", "Banana", "Orange", "Pear"} // 目前的容量是4（长度也是4）
s = append(s, "Strawberry")
fmt.Println(s, cap(s))
```

> 输出：[Apple Banana Orange Pear Strawberry] 8
>
> 解释：直接使用append时，触发**翻倍扩容。**
>
> 如果需要append的元素容量个数大于4个，例如5个，也就是新切片容量已经大于二倍容量8，那么新容量=旧容量+新元素个数
>
> 例如换成：s = append(s, "Strawberry", "A", "B", "C", "D", "E")，那么容量就是10。

**延申：**

如果是

```go
s := make([]string, 5, 7)
s = []string{"Apple", "Banana", "Orange", "Pear"}
s = append(s, "Strawberry")
fmt.Println(s, cap(s))
```

打印结果仍然是： [Apple Banana Orange Pear Strawberry] 8

因为第二行代码是**直接用新的切片字面量赋值**，不是在原有切片上修改。原来那个底层数组（容量 7）直接被丢掉了，**s 现在引用的是一个新的底层数组。**

但是，如果第二行换成

```go
s[0], s[1], s[2], s[3] = "Apple", "Banana", "Orange", "Pear"
```

那容量就还是 7，不会掉到 4，也不会扩容到 8。

------

面试的完整题目是：

```go
s := []string{"Apple", "Banana", "Orange", "Pear"}
s = append(s, "Strawberry")
s[1] = "ananaC"
fmt.Println(s, cap(s))
fmt.Println(s[1])
```

结果：

```go
[Apple ananaC Orange Pear Strawberry] 8 // 将Banana替换成了ananaC
ananaC
```

#### 问题4

使用goroutine实现交替打印字母和数组，中间间隔一秒，字母是大写的A-Z，数字是1-26

```go
func main() {
	var wg sync.WaitGroup
	wg.Add(2)

	letterCh := make(chan bool)
	numberCh := make(chan bool)

	// 打印字母
	go func() {
		defer wg.Done()
		for i := 'A'; i <= 'Z'; i++ {
			<-letterCh
			fmt.Printf("%c ", i)
			time.Sleep(time.Second)
			numberCh <- true
		}
	}()

	// 打印数字
	go func() {
		defer wg.Done()
		for i := 1; i <= 26; i++ {
			<-numberCh
			fmt.Printf("%d ", i)
			time.Sleep(time.Second)
			// 防止死锁
			if i != 26 {
				letterCh <- true
			}
		}
	}()

	// 先启动字母协程
	letterCh <- true

	// 等待两个协程完成
	wg.Wait()
}
```

延申：用两个goroutine和一个channel交替打印出123456

```go
package main

import (
	"fmt"
	"sync"
)

func main() {
	ch := make(chan int) // 只用这一个 channel
	var wg sync.WaitGroup
	wg.Add(2)

	// 打印奇数的 goroutine
	go func() {
		defer wg.Done()
		for {
			n, ok := <-ch
			if !ok {
				return
			}
			if n%2 == 1 { // 轮到我
				fmt.Print(n)
				ch <- n + 1
			} else { // 不是我的回合，打回去
				ch <- n
			}
		}
	}()

	// 打印偶数的 goroutine
	go func() {
		defer wg.Done()
		for {
			n, ok := <-ch
			if !ok {
				return
			}
			if n%2 == 0 { // 轮到我
				fmt.Print(n)
				if n == 6 { // 终止条件：打印到 6 就关闭
					close(ch)
					return
				}
				ch <- n + 1
			} else { // 不是我的回合，打回去
				ch <- n
			}
		}
	}()

	// 发球：从 1 开始
	ch <- 1
	wg.Wait()
	fmt.Println()
}

```

#### 问题5

面试官：我输入一个文档的大小，数字代表多少个字节，我要根据这个数字，把它转换成最接近的字节单位，如B、KB、MB、GB等。例如：

输入：10467028

输出：9.98 MB

```go
func formatSize(bytes int64) string {
    // str := []string{"KB", "MB", "GB", "TB", "PB", "EB"}
    const unit = 1024
    if bytes < unit {
       return fmt.Sprintf("%d B", bytes)
    }
    div, index := int64(unit), 0
    for n := bytes / unit; n >= unit; n /= unit {
       div *= unit
       index++
    }
    // "KMGTPE" 依次代表 KB, MB, GB, TB, PB, EB，bytes不会变，变的是div
    return fmt.Sprintf("%.2f %cB", float64(bytes)/float64(div), "KMGTPE"[index])
    // return fmt.Sprintf("%.2f %s", float64(bytes)/float64(div), str[index])
}
```

Go 的 `for` 循环结构是：

```go
for 初始化语句; 条件表达式; 后置语句 {
    循环体语句
}
```

执行顺序是：

1. **初始化语句**（只执行一次）
2. **判断条件表达式**
   - 如果条件为假，跳出循环
   - 如果条件为真，继续执行
3. **执行循环体语句**
4. **执行后置语句**
5. 跳回第 2 步

### 7.31-比特恐龙

#### 讲一下你的鉴权

> 滴滴代驾面对的用户肯定会非常多，对吧？然后你每次都生成token，然后再去存储到数据库的话，这样对数据库的压力是比较大的，就是你的上限是比较低的，另外Token校验对数据库也会有压力。现在需要你优化一下这部分功能，你会怎么做呢？

1. 使用redis缓存

2. 使用jwt

jwt使用流程：

1. 客户端注册：数据库保存用户的信息
2. 客户第一次登录：服务端需要确认用户身份是否合法，是否和数据库的密码匹配。然后服务端生成JWT Token，并返回给客户端
3. 后续客户端携带Token登录。

#### 问题2：网关鉴权

> 面试官：我现在顾客登录成功了，我要去调其他服务的接口，其他的服务是怎么怎么通过我这个请求的？就是你没有认证方式吗？就是我随便一个人来调用你这个服务，我就能一直调用你的这个服务吗？

目前没有前端鉴权这个功能，后续考虑加入网关来进行鉴权。在这个项目中的微服务之间使用了jwt鉴权，除了登录和获取验证码，其他服务都要经过jwt鉴权。

总结，在实际应用中是组合使用：

- **前端请求使用网关鉴权**：属于外部流量，使用网关先进行鉴权（防止非法流量进入），一般查 Redis 维护 Token 黑名单。
- **内部微服务之间使用JWT**：属于内部流量，使用 JWT 做本地校验，确保即使绕过网关也不能访问。

#### 问题3：添加购物车的错误指正

> 面试官指出，将商品添加到购物车这一过程，不需要分布式事务管理（具体表现是商品库存扣减）

对的，予以改正

#### 问题4：超时订单处理

> 面试官：我给你说一下正常的订单啊，我先创建这个订单，创建这个订单后，就是是否要支付嘛？所以它的状态是未支付，但如果超时了，比如是5分钟或者10分钟超时之后，它就会变成未支付，就自动会关闭订单。如果没有自动关闭订单功能，只要我提交这个订单，我不付款也好，他都能卡死在这里。

这个问题其实是面试官在考你**订单超时自动关闭的设计**，特别是**防止库存被长期占用**的问题。

**实现方案：使用延迟任务来实现**

创建订单时，订单初始状态是未支付，我们会在订单系统中设置一个**超时时间**，比如 10 分钟。
订单创建后会同时写入一个**延迟任务**（消息队列延迟队列或 Redis 延迟队列），超市时间到达后检查订单状态：

- 如果已支付，直接结束任务；
- 如果未支付，更新订单状态为“已关闭”，并释放之前预扣的库存。

**技术实现：**

- **Redis ZSet / Stream** 实现延迟队列
- **时间轮**（如 `github.com/RussellLuo/timingwheel`）

```go
package main

import (
	"fmt"
	"sync"
	"time"
)

type Order struct {
	ID        int
	ExpiresAt time.Time
}

// 时间轮槽
type Slot struct {
	mu     sync.Mutex
	orders []Order
}

func (s *Slot) AddOrder(order Order) {
	s.mu.Lock()
	defer s.mu.Unlock()
	s.orders = append(s.orders, order)
}

func (s *Slot) GetOrders() []Order {
	s.mu.Lock()
	defer s.mu.Unlock()
	orders := s.orders
	s.orders = nil // 清空槽
	return orders
}

// 时间轮结构
type TimeWheel struct {
	interval time.Duration // 槽间隔
	slots    []*Slot       // 槽数组
	pos      int           // 当前指针位置
	ticker   *time.Ticker
	stopCh   chan struct{}
}

func NewTimeWheel(slotNum int, interval time.Duration) *TimeWheel {
	slots := make([]*Slot, slotNum)
	for i := range slots {
		slots[i] = &Slot{}
	}
	return &TimeWheel{
		interval: interval,
		slots:    slots,
		pos:      0,
		stopCh:   make(chan struct{}),
	}
}

func (tw *TimeWheel) Start() {
	tw.ticker = time.NewTicker(tw.interval)
	go func() {
		for {
			select {
			case <-tw.ticker.C:
				tw.tick()
			case <-tw.stopCh:
				tw.ticker.Stop()
				return
			}
		}
	}()
}

func (tw *TimeWheel) Stop() {
	close(tw.stopCh)
}

func (tw *TimeWheel) tick() {
	slot := tw.slots[tw.pos]
	orders := slot.GetOrders()
	if len(orders) > 0 {
		fmt.Printf("[时间轮] 槽 %d 触发，批量关闭订单: ", tw.pos)
		for _, order := range orders {
			fmt.Printf("#%d ", order.ID)
		}
		fmt.Println()
	}
	tw.pos = (tw.pos + 1) % len(tw.slots)
}

func (tw *TimeWheel) Add(order Order) {
	delay := order.ExpiresAt.Sub(time.Now())
	steps := int(delay / tw.interval)
	slotIndex := (tw.pos + steps) % len(tw.slots)
	tw.slots[slotIndex].AddOrder(order)
}

func main() {
	tw := NewTimeWheel(8, time.Second) // 8个槽，每个槽间隔1秒
	tw.Start()

	// 模拟10个订单，每个5秒后超时
	for i := 1; i <= 10; i++ {
		order := Order{
			ID:        i,
			ExpiresAt: time.Now().Add(5 * time.Second),
		}
		tw.Add(order)
		fmt.Printf("[新增订单] #%d 超时: %v\n", order.ID, order.ExpiresAt)
	}

	// 运行10秒后停止
	time.Sleep(10 * time.Second)
	tw.Stop()
}
```

**使用redis streams**

```go
package main

import (
	"context"
	"fmt"
	"log"
	"strconv"
	"time"

	"github.com/redis/go-redis/v9"
)

var ctx = context.Background()

const (
	StreamKey   = "order_timeout_stream"
	GroupName   = "order_timeout_group"
	ConsumerName = "consumer_1"
)

func createOrder(rdb *redis.Client, orderID string, ttl time.Duration) {
	expireAt := time.Now().Add(ttl).UnixMilli()
	_, err := rdb.XAdd(ctx, &redis.XAddArgs{
		Stream: StreamKey,
		Values: map[string]interface{}{
			"orderId":  orderID,
			"expireAt": expireAt,
		},
	}).Result()
	if err != nil {
		log.Printf("写入延时任务失败: %v", err)
	}
	log.Printf("订单创建: %s, 超时: %v", orderID, ttl)
}

func readAndProcess(rdb *redis.Client) {
	res, err := rdb.XReadGroup(ctx, &redis.XReadGroupArgs{
		Group:    GroupName,
		Consumer: ConsumerName,
		Streams:  []string{StreamKey, ">"},
		Count:    10,
		Block:    0, // 阻塞读取
	}).Result()

	if err != nil && err != redis.Nil {
		log.Printf("读取消息失败: %v", err)
		return
	}

	for _, stream := range res {
		for _, message := range stream.Messages {
			orderID := message.Values["orderId"].(string)
			expireAtStr := message.Values["expireAt"].(string)
			expireAt, _ := strconv.ParseInt(expireAtStr, 10, 64)

			if time.Now().UnixMilli() >= expireAt {
				// 到期 -> 关闭订单
				closeOrder(orderID)
				// ACK 删除任务
				_ = rdb.XAck(ctx, StreamKey, GroupName, message.ID).Err()
			} else {
				// 未到期 -> 可以选择跳过或重新插入队列
				log.Printf("订单未到期: %s", orderID)
			}
		}
	}
}

func closeOrder(orderID string) {
	log.Printf("关闭订单: %s", orderID)
	// TODO: 执行库存回滚、更新订单状态等
}

func main() {
	rdb := redis.NewClient(&redis.Options{
		Addr: "localhost:6379",
	})

	// 初始化 Consumer Group（存在则忽略错误）
	_ = rdb.XGroupCreateMkStream(ctx, StreamKey, GroupName, "$").Err()

	// 模拟创建订单
	createOrder(rdb, "order123", 10*time.Second)
	createOrder(rdb, "order456", 15*time.Second)

	// 启动消费者
	for {
		readAndProcess(rdb)
		time.Sleep(1 * time.Second)
	}
}
```

#### 讲一下区块链毕业设计

略

### 8.14-卓拙科技

#### TLS握手过程中，TLS之前是否会进行TCP握手？

在 TLS 握手前，必须先完成 **TCP 三次握手**。

#### 为什么要用会话密钥，直接用前面的非对称密钥可以吗？

**非对称加密复杂度高，对CPU的消耗大**，加密过程比较耗时。会话密钥是对称加密，加密速度快。而在日常会话中的数据量比较大，因此会话密钥更能满足需求。

#### 讲一下HTTPS的工作过程？

HTTPS 是 HTTP协议 加上 TLS 加密协议而得到的，它的底层仍然使用TCP协议。

客户端和服务器需要先完成 TCP 三次握手，然后进入 TLS 握手，在此过程中，双方会生成对应的会话密钥。

后续所有 HTTP 请求和响应都会使用会话密钥进行加密传输，从而保证数据的 **机密性**。

#### wireshark有用过吗？

略

#### data race 检测，除了 pprof 还有没有其他方式？

其实 pprof 本身并不是用来检测 data race 的。还有Trace工具。

还可以Go内置的工具，在编译时加上 `-race` 参数，运行时会监控内存访问，检测到多个 goroutine 同时访问共享变量且有写操作时，会直接输出警告和调用栈。

------

简单说：

- `go test -race` 是 “找有没有并发错误（数据竞争）”；
- `pprof` 是 “找 CPU / 内存消耗在哪个函数上”；
- `Trace` 是 “看这个函数为什么慢（是 goroutine 阻塞了？还是 CPU 不够用？）”。

#### 如何实现一个防火墙拦截黑名单域名？（自定义的方式）

1. 定义一个线程安全的 map 结构用来存储黑名单域名。
2. 搭建一个HTTP**代理服务器**，让所有网络流量经过代理中转。
3. 在代理处理流程中，从请求中提取目标域名。
4. 将提取到的域名与黑名单进行比对，如果匹配则执行拦截操作，返回拒绝访问的响应给客户端。
5. 对于允许访问的请求，建立客户端与目标服务器的双向数据通道，转发来往数据，保持正常通信。

#### 多个协程里面可以使用同一个wait()吗？

可以。`WaitGroup` 设计的目的就是在多个 goroutine 中 **协同等待**。

#### 如何用最快的方式在10个连接里面找出一个ping时间最短的？

我会开启 10 个 goroutine 并发的去检测 这 10 个连接，对每个连接记录它的响应时间，一旦得到了 pong 响应就立马将结果写入一个无缓冲 channel，再使用一个goroutine来监听这个channel。channel里面的第一个值就是最快的连接写入的。然后通知其他还没有响应的连接不用再尝试了。

### 8.19-比特鹰

#### 微服务治理的理解，都包含什么?

服务注册与发现、负载均衡、熔断与限流、链路追踪等。

#### 为什么协程比线程更轻量级？

协程是用户级的线程，初始栈大小只有2KB，线程是由操作系统创建的，大概有1M。

------

#### 了解过docker和K8S吗？

否

#### 了解过消息队列吗？

kafka

#### 简单讲一下Redis的RDB和AOF各自的工作原理和优缺点？

1、RDB是全量快照形式，优点是RDB文件较小，所以**恢复速度很快**，但是 redis崩溃时，容易丢失快照数据。

> 为什么会丢数据？
>
> - 假设上次 RDB 快照在 12:00:00 创建，Redis 在 12:05:00 崩溃。
> - 那么 **12:00:01 ~ 12:05:00** 期间的所有写操作都没有落盘到 RDB 文件中。
> - 重启时只能加载最近一次快照的数据，其余写操作就丢失了。

2、AOF是**命令追加**形式，优点是数据安全（可以做到完全不丢失数据-always模式），缺点就是AOF文件会很大，所以恢复很慢。

#### 讲一下Redis达到内存限制的时候，常见的淘汰策略？

Redis 的淘汰策略（**Eviction Policy**）是指当 **内存达到上限**时，Redis 如何选择删除某些 key 来释放空间。

**1、不淘汰（noeviction）**

内存满了，写命令（SET/INCR等）返回错误，不会删除任何 key。

**2、 LRU（最近最少使用）**：记录时间戳，维护一个链表结构。

- volatile-lru：只对设置了过期时间的 key 进行 LRU 淘汰
- allkeys-lru：对所有 key 进行 LRU 淘汰
- 原理：Redis 会维护一个近似 LRU 算法（**随机采样** 5~10 个 key，选择最久未访问的 key 淘汰）

**3、LFU（最少使用次数/频率）**

- volatile-lfu：只对设置了过期时间的 key 淘汰
- allkeys-lfu：对所有 key 淘汰
- 原理：Redis 使用**计数器**记录 **key 被访问的频率**，会对key进行**随机采样。**淘汰访问次数最少的 key。
- **优点：热点 key 不会被误删。**

**4、TTL（过期时间）淘汰**

- volatile-ttl：只对设置了过期时间的 key 淘汰，**优先删除快过期的 key。**
- 特点：避免删除还远未过期的 key。适合缓存场景，**保证热点数据不被误删。**

**5、随机策略**

- volatile-random：随机淘汰设置了过期时间的 key
- allkeys-random：随机淘汰所有 key
- 特点：算法简单，性能高。**缺点是可能删除热点数据。**

#### 你一般怎么去优化MySQL的查询性能？

通常优化SQL语句和索引。需要结合explain执行计划。

- 改写SQL语句，比如避免select *；
- 创建合适的索引，主要是联合索引；
- 使用索引时遵循最左匹配原则；
- 使用索引时尽量索引覆盖，这样就不需要回表。

#### 讲一下B+树的结构特点？

1. B+树是一棵平衡多叉树；
2. 非叶子节点只存储索引，索引是有序的；
3. 叶子节点存放真正的数据，数据是有序的；
4. 相邻叶子节点通过 **双向链表** 连接。

**🧩 一、两种索引类型的区别**

| 索引类型                        | 叶子节点存什么                      | 说明                                       |
| ------------------------------- | ----------------------------------- | ------------------------------------------ |
| **聚簇索引（Clustered Index）** | 索引键（通常是主键） + **整行数据** | 每张 InnoDB 表的主索引，叶子节点就是数据页 |
| **二级索引（Secondary Index）** | 索引键（如 name） + **主键值**      | 不存整行数据，查询时要通过主键“回表”取数据 |

**附加：B树、B+树、B*树的区别？**

- B树也称B-树，它的非叶子节点也存放数据，节点之间没有指针相连；
- B*树的非叶子节点之间也有指针相连。应该也是双向指针。

#### 附加：MySQL为什么用B+树，而不用B树？ 

总结：B树的非叶子节点也存放数据，因此在相同的数据量下，B树的非叶子节点的扇出更小，树的高度就更高，所以查询效率更低。

解释：数据库中每页的大小是固定的，通常是16KB。B树的非叶子节点既存储索引值，也存储数据，B+树的非叶子节点仅存储索引值。因此在相同的数据量下，B树的非叶子节点存储的索引更少，因此扇出更小，树的高度也就更高，查询效率就更低。

严格来说，非叶子节点存储的是**索引项，包括键值+指针。**

#### 讲一下传统架构、微服务架构、云原生架构的区别？

**1、传统架构（单体架构）**

- 特点：整个系统是一个整体（All-in-One），代码、功能、部署都打包在一个应用里。
- 优点：开发、部署简单，适合业务规模小的系统。
- 缺点：扩展性差；容错性不好，某个模块出问题可能影响整个系统。

**2、微服务架构**

- 特点：把系统拆分成多个独立服务，通过 gRPC 等进行通信。
- 优点：**扩展性强**，服务可以独立开发、部署、扩容；**容错性更好**，某个服务出问题不会导致全系统崩溃。
- 缺点：服务治理复杂（注册发现、熔断、限流、链路追踪）；对运维要求更高。

**3、云原生架构**：融合了微服务、容器化、自动化编排等。

- 特点：以 **容器化、自动化、弹性伸缩** 为核心，通常基于 Kubernetes 等平台来管理服务。强调 DevOps 和**基础设施即代码。**
- 优点：运维自动化程度高，**弹性伸缩**方便，快速适应业务波动；具备跨云/多云能力；标准化（CNCF 生态）。
- 缺点：学习成本和实施成本高，对团队在容器化、K8s、CI/CD、服务网格（如 Istio）等方面有较高要求。

✅ **总结对比：**

- **传统架构** → 一体化，适合小型项目，简单但不易扩展。
- **微服务架构** → 模块化，适合中大型项目，可扩展但运维复杂。
- **云原生架构** → 微服务 + 容器 + 自动化编排，适合大规模和高弹性场景。

### 8.28-紫讯信息

#### Golang相对于其他语言的优势在哪里？

- 语法更简洁。
- 并发实现简单，支持协程，并且实现了高效的GMP调度模型。
- 有高效的垃圾回收机制，支持并行垃圾回收，垃圾回收效率比比 Java 或 Python 更高。

#### 你在写项目的过程中，有没有自己觉得比较好用的第三方包？或者说自己比较喜欢用的一些第三方包？

web框架：Gin

数据库：Gorm

微服务：go-micro、Kratos、go-zero

中间件：go-redis/redis、Shopify/sarama（kafka客户端）

配置管理：Viper

日志管理：uber-go/zap

监控：prometheus/client_golang

链路追踪：jaeger-client-go

参数校验：go-playground/validator

#### 讲一下什么是协程？什么是线程？他们之间有什么关系？

协程是用户态的轻量级线程，线程是**操作系统调度**的基本单位。

**协程最终要绑定到线程之上才能运行**，这个过程在Go语言中通过GMP模型进行调度。

#### 在 Go 语言中怎么保证并发安全？

锁、原子操作、sync包的其他工具、channel通信。

#### map是并发安全的吗？为什么？

不是，原因是 map 为了追求性能，并没有在内部加锁。如果要保证并发安全，可以通过加锁、使用 sync.Map来保证。

#### 如果对map做一些并发操作，它会导致什么什么后果？

- 程序崩溃 (panic)：`fatal error: concurrent map writes`
- 数据竞争（data race）：多个 goroutine 同时执行时会**互相覆盖**，导致最终结果错误。

#### slice 是并发安全的吗？为什么？

切片不是并发安全的，尤其是在进行**读写操作或动态扩容时**，可能会导致数据覆盖或丢失。

**切片的线程安全问题主要体现在以下方面：**

1. **并发读写特定索引**：多个 Goroutine 同时对切片的同一索引进行写操作时，可能会发生数据覆盖。例如，两个 Goroutine 同时向同一索引写入不同的值，最终只有一个值会被保留。
2. **动态扩容**：在并发场景下，多个 Goroutine 可能**同时触发扩容**，底层数组扩容时重新分配内存，但另一个 goroutine 还在用旧的地址，产生数据错乱。
3. 还有比如扩容时，长度、容量字段在并发修改时被破坏，导致 panic。

**如何解决？**

1. 加锁：**append的时候加锁；**
2. 使用channel串行化操作：主要做法是先把值发送到channel里，然后遍历channel，将值append到slice中；

#### 切片作为参数，是值传递还是引用传递？

Go语言中所有的传递都是值传递，只不过有些参数类型的值实际存储的是指针，所以修改会影响底层数据。

#### 那如果是值传递的话，为什么我把这个切片传到了另一个函数里面，我然后他去改变这个切片里面的东西，在之前的函数里面的这个切片也会有相应的改变呢？

切片本身是值传递，但切片里面有指向底层数组的指针，而**底层数组是共享的**，当你通过切片修改元素（`s[i] = x`）时，实际上修改的是 **底层数组**，因此所有指向这个数组的切片都会看到变化。

但是，如果改变了切片的结构（例如扩容），使Go自动 **分配了新的底层数组**，那原本的切片是不受影响的。

#### Go里面的pprof有用过吗？你大概描述一下使用pprof能看到哪些东西？

`pprof` 是 Go 自带的性能分析工具，用于分析 **CPU、内存、阻塞、goroutine 等性能问题**。可以帮助我们找出程序 **瓶颈、内存泄漏、goroutine 堆积** 等问题。

**pprof 能查看的主要内容：**Profile 的意思是对程序运行情况的 **性能剖析或分析报告**。

1. **CPU Profile**
   - 查看程序在**哪些函数**花费了最多 CPU 时间。
   - 使用场景：分析热点函数、优化性能。
2. **Heap Profile（内存分析）**
   - 查看内存分配情况、**哪个函数分配了多少内存。**
   - 使用场景：分析内存泄漏、过度分配。
3. **Block Profile**
   - 查看阻塞操作，例如锁竞争。
   - 使用场景：优化并发程序中的锁竞争问题。
4. **Goroutine Profile**
   - 查看程序中所有 **goroutine 的栈信息。**例如调用栈。
   - 使用场景：定位 goroutine 泄漏或死锁问题。
5. **Threadcreate Profile**
   - 查看系统线程创建情况。

------

 **CPU Profile** 和 **Heap（内存）Profile** 的区别？

- CPU Profile 记录的是 **程序执行函数所消耗的 CPU 时间**，也就是函数调用栈占用 CPU 的比例。
- Heap Profile 记录的是 **程序中哪些函数分配了多少内存**，以及这些内存是否还在使用。

------

**goroutine 的栈信息是什么？**

栈信息就是 **当前 goroutine 的调用链 / 执行状态**：

一个典型的 goroutine 栈信息包含以下要素：

1. **编号**：每个 goroutine 的唯一标识（如 `goroutine 1`）。
2. **状态**：goroutine 的当前状态（如 `running`、`sleeping`、`waiting` 等）。
3. **函数调用链**：从当前执行的函数向上追溯的完整调用路径，包含：
   - 函数名（如 `main.main`）
   - 文件名及行号（如 `main.go:23`）

#### 讲一下init()函数的执行顺序？

```css
我们的项目 (main) 
    └── 第三方包A
            └── 第三方包B
```

每个包都有一个 `init()`，执行顺序如下：

1. **初始化最底层依赖**
   - 第三方包 B 的 `init()` 先执行
2. **初始化上层包**
   - 第三方包 A 的 `init()` 执行
3. **初始化 main 包**
   - main 包的 `init()` 执行
4. **执行 main.main()**

#### 使用定时器Timer需要注意些什么？

当不再需要定时器时，一定要及时Stop()，否则会导致资源泄漏。

**解释：**

**1、`Timer` 的底层结构与资源占用**

`time.Timer` 的底层实现包含：

- 一个用于接收**超时事件**的通道 `C`（`<-chan time.Time`）；
- 关联的**定时器逻辑**（由 runtime 维护的计时器队列）；
- 可能被阻塞的 goroutine（若等待 `C` 中的事件）。

当 `Timer` 未被停止时：

- 即使程序不再使用该 `Timer`，runtime 仍会在内部计时器队列中保留其引用，**持续占用内存；**
- 如果通道C无值且定时器不再触发，将导致**监听该通道的 goroutine 一直阻塞（若存在）**，无法退出。

**2、内存泄漏的具体表现**

- **`Timer` 本身的内存无法释放**：未停止的 `Timer` 会被 runtime 的计时器系统引用，导致 **GC 无法回收其占用的内存**（包括 `C` 通道和内部结构）。
- **关联的 goroutine 泄漏**：若有 goroutine 正在执行 `<-timer.C` 等待事件，而 `Timer` 未触发或未被正确停止，该 goroutine 会一直阻塞，成为 “僵尸 goroutine”，其占用的栈内存和资源也无法释放。

#### HTTP协议跟TCP协议分别是什么？他们之间是什么关系？大概跟我说一下。

**是什么？**

- HTTP 是应用层协议，用来规定客户端和服务器之间**通信的格式**，比如请求和响应的规则。
- TCP 是传输层协议，提供可靠的、面向连接的数据传输。

**联系：**

- HTTP 是建立在 TCP 之上的，HTTP 把请求/响应数据交给 TCP，由 **TCP 负责可靠传输。**

#### 你还提到了TLS协议，那你知道TLS协议是运行在哪一个步骤上吗？

TLS 协议运行在 **应用层和传输层之间**，它在 TCP 提供可靠连接的基础之上，负责 **加密传输**。

------

**TLS握手和TCP握手是哪个先哪个后？**TCP 握手先于 TLS 握手。

#### 那UDP协议又是一个什么样的角色呢？

UDP也是传输层的协议，但是UDP协议是无连接的、不可靠的协议。

#### MySQL的索引大概是一个什么东西？然后它的作用是什么？然后它的底层原理大概是什么样的？你大概讲一下。

**1、索引是什么？**

MySQL的索引类似于书的目录，它是一种 **数据结构**。我们通常讲的索引就是B+树结构。

**2、索引的作用？**

提高查询效率，因为它可以快速定位到数据行。

**3、索引的底层？**

在 InnoDB 引擎里，索引的底层是 **B+ 树**。结构特点：

- B+ 树是一棵多叉平衡树。
- 非叶子节点不存储实际数据值，只起到导航的作用（往左还是往右）。
- 所有数据都存在叶子节点，叶子节点之间通过双向链表连接（**方便范围查询**）。

#### 解释一下为什么使用索引能提高查询效率？

如果没有索引，MySQL 查询数据时只能 全表扫描。如果使用了索引，比如B+树索引，因为非叶子节点的索引键是有序排列的，所以查找过程就可以**类似于二分查找**那样，不断的缩小范围。

#### 既然我们都知道索引，那在我们的SQL语句中要怎么样尽量用上索引呢？你能给我描述一下吗

在写 SQL 的时候，要尽量让查询能够命中索引，主要有以下几点注意：

1. **条件字段走索引**

   - 在 `WHERE` 子句、`JOIN` 条件、`ORDER BY`、`GROUP BY` 中使用索引列。
   - 比如常见的主键索引、唯一索引、普通索引、联合索引。

2. **避免对索引字段使用函数或计算**

   - 如 `WHERE DATE(create_time) = '2025-09-27'` 就不会走索引，应该写成
      `WHERE create_time >= '2025-09-27 00:00:00' AND create_time < '2025-09-28 00:00:00'`。
   - 同理，`WHERE id + 1 = 10` 不走索引，应该写成 `WHERE id = 9`。

3. **保持索引列的数据类型一致，避免隐式转换**

   - 比如 `WHERE phone = 123456`，如果 `phone` 是 `VARCHAR` 类型，会触发全表扫描。

4. **联合索引遵循最左匹配原则**

   - 如果有 `(a, b, c)` 联合索引，那么 `WHERE a=...`、`WHERE a=... AND b=...` 都能用上索引。
   - 但是只用 `b=...`，则无法利用这个联合索引。

5. **模糊查询尽量用前缀匹配**

   - `LIKE '%abc'` 无法使用索引，`LIKE 'abc%'` 可以利用索引。
   - 如果必须模糊查询，可以考虑 `FULLTEXT` 或者搜索引擎（如 Elasticsearch）。

6. **控制 OR 和 IN 的使用**

   - `OR` 可能导致索引失效，必要时可以用 `UNION ALL` 替代。
   - `IN` 如果是小范围常量值集合，通常能用索引，但过大会退化成全表扫描。

7. **能用覆盖索引最好**

   - 如果查询的字段都在索引里，就不需要回表，可以加快速度，比如：

     ```sql
     SELECT id, name FROM user WHERE age = 20;
     ```

     如果 `(age, id, name)` 是联合索引，就能直接走覆盖索引。

8. **避免在索引列上使用 `IS NULL` 或 `!=`**

   - 这种条件通常无法高效利用索引。

#### 你有了解过MySQL事务的底层实现原理吗？比如底层是怎么实现事务的ACID？请你讲一下。

1. **原子性 (Atomicity)**
   - 原子性是通过 **Undo Log（回滚日志）** 来保证的。
   - **每当事务对数据做修改时**，会先写一份相应的 undo log，如果事务失败或回滚，就通过 undo log 把数据恢复到修改前的状态。
2. **一致性 (Consistency)**
   - 一致性是由 **原子性 + 持久性 + 隔离性**共同保证的。
3. **隔离性 (Isolation)**：多个事务并发执行时，互不干扰。
   - 隔离性由 **锁机制** 和 **MVCC**来保证。
   - 锁包括行锁、间隙锁、Next-Key Lock，**保证并发事务不会互相干扰。**
   - MVCC 中，不同的隔离级别生成的**读视图的时机**不同，从而对数据的可见范围不同。
4. **持久性 (Durability)**
   - 持久性主要靠 **Redo Log** 来保证。
   - 写数据时，先写 redo log，再写到数据页。这就保证了即时系统崩溃，也能通过redo log恢复数据，保证数据不丢失。

#### GRPC是基于什么协议实现的，你了解吗？

gRPC 是 **基于 HTTP/2 协议** 来实现的远程过程调用框架。

1. **通信协议**
   - gRPC 使用 **HTTP/2** 作为通信协议。
   - HTTP/2 的特性（多路复用、头部压缩、双向流、服务端推送）非常适合高效的 RPC 调用。
   - 比如：一个 TCP 连接上可以并行多个请求，不需要像 HTTP/1.1 一样排队。
2. **序列化协议**
   - gRPC 默认使用**Protobuf** 来定义接口和序列化数据。
   - Protobuf 是一种二进制序列化方式，体积小、性能高。

**总结：**gRPC 是 **基于 HTTP/2 协议实现通信，使用 Protobuf 作为序列化协议**。

------

**延申：HTTP2和其他HTTP协议的区别？**

1. **HTTP/1.0**

   - **无连接：**每次请求都要建立 TCP 连接，效率很低。
   - **队头阻塞：**由于HTTP1.0规定下一个请求必须在前一个请求响应到达之前才能发送，假设前一个请求响应一直不到达，那么下一个请求就不发送，后面的请求就阻塞了。
   - **不支持长连接**，也没有 Host 头。

2. **HTTP/1.1**

   - **引入了长连接**，一个 TCP 连接可以复用多个请求，避免频繁建立连接。
   - 支持 **管道传输**，但是由于队头阻塞（前一个请求没回来，后面请求也卡住），实际应用不多。
   - 新增了缓存控制、分块传输、Host 头字段等。

3. **HTTP/2（gRPC 就是基于这个的）**

   HTTP/2.0协议几乎都是基于HTTPS的，**更加安全。**完全解决了HTTP/1.1中的**队头阻塞**问题。

   - **二进制分帧**：HTTP/2 把传输的数据分成二进制帧，并对帧进行编号和结构化处理，再通过单一 TCP 连接传输。
   - **多路复用**：同一个 TCP 连接里可以并发多个请求，不会互相阻塞，解决了 HTTP/1.1 的队头阻塞问题。
   - **头部压缩（HPACK）**：请求头用压缩算法（Huffman 编码等），减少带宽消耗。
   - **服务端推送**：支持服务端推送（Server Push），比如浏览器请求一个 HTML，服务端可以主动推送 JS/CSS，而不需要客户端再次请求。

   但是，因为TCP面向字节流传输，而且保证传输可靠性和数据的完整性，还是会导致TCP队头阻塞。

4. **HTTP/3（拓展一下，加分）**

   为了解决HTTP/2.0中TCP造成的队头阻塞问题，HTTP/3.0直接放弃使用TCP，**将传输层协议改成UDP**；但是因为UDP是不可靠传输，所以这就需要**QUIC实现可靠机制。**

#### 那你觉得 gRPC 的整体优势在哪里？

我觉得 gRPC 的优势主要有以下几点：

1. **HTTP/2 传输效率更高**
   - 基于 **HTTP/2**，支持**多路复用**、头部压缩和双向流式通信。
   - 避免了 HTTP/1.1 的队头阻塞问题，延迟低、吞吐量高。
2. **序列化体积更小**
   - 默认使用 **Protobuf**，序列化后的**数据体积小**、解析快，比 JSON、XML 更高效。
   - 对于大规模微服务之间频繁调用，非常节省带宽和 CPU。
3. **支持多种语言**：直接使用对应的命令就可以做到
   - gRPC 官方支持十几种主流语言（Go、Java、Python、C++、Node.js 等），**非常适合多语言微服务架构。**
4. **具有规范的语法**：
   - 使用 Protobuf 定义**服务接口和数据结构**，客户端和服务端可以自动生成代码，避免了接口不一致的问题。
5. **天然支持流式通信**
   - 支持四种调用方式：单请求单响应、服务端流、客户端流、双向流，非常适合实时场景，比如聊天、视频推流、物联网数据上报等。
6. **生态完整**
   - 可以和 负载均衡、认证、监控、链路追踪、服务发现 等组件结合，方便构建生产级微服务体系。

#### grpc协议和http协议相比有什么优势？为什么已经有了http还要选择grpc？

“HTTP 协议” 通常默认指 **HTTP/1.1**。grpc有以下优势：

**1、 传输效率更高：二进制协议 vs 文本协议。**

- **gRPC**：基于 **Protobuf（二进制序列化协议）** 编码数据，体积比 JSON/XML 小，解析速度快。
- **HTTP**：通常使用 JSON格式，属于文本协议，体积大、解析慢；

**2、底层协议更优：**http2优于http1.1。

- REST 基于 HTTP/1.1，请求-响应模型，**容易出现队头阻塞；**
- gRPC 基于 HTTP/2，有**多路复用机制**，完全解决了队头阻塞问题，一个 TCP 连接上可以并发多个请求，延迟更低。

**3、具有规范的语法规则**：自定义数据结构、服务接口等。

**4、设计目的更契合服务间通信**

- **gRPC**：设计目标是**服务端到服务端的高效通信**。
- **HTTP**：更适合**用户端到服务端的通信**。

#### 再讲一下Golang的并发调度模型？

golang的并发调度模型是GMP调度模型。G就是指goroutine，是轻量级的线程，也就是通常所说的协程，M是指操作系统线程、P是指逻辑处理器。用一句话概括：GMP 模型就是将协程作为调度单位，通过逻辑处理器 P 将协程绑定到系统线程上去执行。由于每个协程占用的内存比较小，再加上GMP模型支持抢占式调度，所以大量的协程就能够轻松实现高并发。

#### 真正干活的是G、M、P中哪个？

真正干活的是 M。最终是 M 在执行 G 里的代码。

#### 你的项目中用的是GRPC通信，那你是如何保证服务的安全的？

GRPC中基于HTTP2.0，本身就加入了TLS保证通信安全，在服务间调用时增加了JWT的认证机制。

#### 你的 jwt token 存在哪里？是通过GRPC传输的吗？（用户token）

服务端不存储，只存储secret。客户端存在localstorage；

答：短期token存储在客户端全局变量，长期token客户端使用系统安全存储，服务端则加密存储在redis里。关于传输，通过GRPC的响应获取token即可（比如第一次登录）。之后，如果需要携带，都是将token放在metadata里面，传输给服务端，区别在于只有短期token过期时，才会加载长期token，用于刷新短期token。

1. 服务端生成 jwt Token 后，放在body里面返回给客户端，本项目加入了TLS保证通信安全。
2. 客户端收到 token 后，将其存放在一个**全局变量**里面（这是针对短期token）。长期token需要先存储在服务端的DB/Redis里面。客户端首次收到时，使用系统级安全存储，项目中通过`go-keyring` 库调用**系统密钥环**存储refresh Token。
3. 客户端请求时，将 token 放在 metadata 里面，然后加入到 ctx 里面传输给服务端；
4. 服务端收到数据后，从ctx里面解析出token，进行校验。

用户提交用户名/密码到 auth 服务，服务验证通过后用私钥/secret 生成 **Access Token**（短期）和 **Refresh Token**（长期，加密存在 Redis 的哈希里以便撤销），把 Access Token 和 Refresh Token 通过rpc响应 返回。之后客户端每次请求把 Access Token 放在metadata里，服务端拦截器提取 token，验证签名（secret 或公钥），若通过则将 claims 注入上下文并继续处理；当 Access Token 过期时，客户端调用 refresh 接口（带上 refresh token），服务端校验 refresh token 并颁发新的 access token（并可旋转 refresh token）。

#### 那你的 jwt token的生成，生成的规则或者是生成的时机是在是在什么时候？（用户token）

在用户登录时，服务端就要生成token，然后随登录成功的resp发送给客户端。随后客户端就可以携带token进行后续操作了。

#### 你这里的jwt token跟用户登录有关，那如果单从微服务来考虑，一个微服务调了另一个微服务，为什么会用一个跟用户有关的token去调呢？怎么去调整这个问题？（服务间token）

结合 Consul 和 JWT 实现微服务访问控制的整体流程可分为 5 个核心步骤：

1. **服务身份注册与授权配置**

   每个微服务在系统中注册唯一服务 ID（如`user-service`），并在授权中心配置其**可调用的目标服务列表**（如`user-service`允许调用`order-service`）。同时，为每个服务分配唯一密钥（用于向授权中心证明身份）。

2. **调用方申请 JWT 令牌**

   调用方服务启动时，使用自身服务 ID 和密钥向 JWT 授权中心申请令牌。授权中心验证身份合法后，生成包含以下信息的 JWT 令牌：

   - 调用方服务 ID（`service_id`）

   - 允许调用的目标服务列表（`allowed_services`）

   - 过期时间（短期有效，如 10 分钟）

     令牌用**授权中心的私钥**签名后返回给调用方。

3. **调用方通过 Consul 发现目标服务**

   调用方需要调用其他服务时，先通过 Consul 查询目标服务的网络地址（IP + 端口）。

4. **调用方携带令牌发起请求**

   调用方在向目标服务发起 HTTP 请求时，将 JWT 令牌放入**GRPC 元数据（metadata）** ，即"authorization": "Bearer "中，传递给被调用方。

5. **被调用方验证令牌与权限**

   被调用方收到请求后，通过以下步骤验证：

   - 从 metadata 中提取 JWT 令牌，用**授权中心的公钥**验证签名合法性（防止篡改）；
   - 检查令牌是否过期；
   - 解析令牌中的`service_id`（调用方身份）和`allowed_services`（权限列表）；
   - 验证当前服务 ID 是否在`allowed_services`中，若在则允许访问，否则拒绝（返回 403）。

通过这套流程，确保只有被授权的服务才能调用目标服务，实现了基于服务身份的访问控制。

------

**认证中心：**使用轻量的**ORY Hydra**。更专业的就是 Keycloak。

#### 讲一下 websocket 协议？

- WebSocket 是一种建立在单个 TCP 连接上的**全双工通信**协议。传统的实时通信是通过轮询、长轮询的方案。
- webSocket 通过 HTTP 升级而得到，期间会经过websocket握手。
- WebSocket 使用 **帧（Frame）** 的形式传输消息，操作码（Opcode）用于标识帧的类型，包括文本帧、二进制帧等；

建立好连接后，客户端和服务器可**同时、随时**发送数据。

#### 你再稍微详细一点描述，怎么使用websocket进行消息的发送和接收？

我使用两个goroutine来进行消息的发送和接收，每个用户都是一个通信节点。在发送消息时通过**targetID**来决定要发给谁，targetID有可以是某个用户，或者某个群组。

#### 再讲一下你的心跳检测下线机制，你是通过timer来清理超时连接？

在本服务器节点中，通过一个goroutine启动一个Timer，定时器会定时执行一个**清理超时连接**的函数，服务端通过这个函数是遍历所有的websocket连接来检测是否超时，如果节点还活跃（进行消息发送等），就更新自己的时间戳，给自己续命。

如果连接太多，可以随机选取几个，或者设计LRU等结构；

------

目前改用堆结构替代了传统的定时器扫描方式，

### 9.2-河南一个理念

#### MySQL的主从同步，底层是怎么实现的？

1. 主库执行**写操作**时，会把变更记录到 **二进制日志（binlog）**。
2. 从库有一个 **IO 线程** 会持续获取主库的 binlog 日志，然后写入本地 **中继日志（relay log）**。
3. 从库的 **SQL 线程** 读取中继日志并执行其中的 SQL，从而完成数据同步。

初次搭建从库时，需要使用 `mysqldump` 或物理备份把主库的 **全量数据** 导入，从库才可以开始增量同步 binlog。此外，同步机制还会记录 binlog 的 **文件名和偏移量**，确保从库能够从正确位置同步。

**附加：为什么需要中继日志？（个人附加问题）**

首先，中继日志是作为从库的本地缓存。那么它就有以下几个作用：

1. 解耦 **拉取和执行binlog**的操作；
2. 支持 **断点续传**，宕机后能从上次执行位置继续操作；
3. 降低对主库依赖；

**附加：断点续传中，如果是IO线程和主库断开了呢？如何续传？**

1. IO 线程会 **自动尝试重连**（默认每隔 `MASTER_CONNECT_RETRY` 秒）。
2. 重连后会告诉主库：
   - 自己上次读到的 **binlog 文件名** 和 **binlog position**（偏移量）。
3. 主库就会从这个位置开始继续发送 binlog，避免重复或遗漏。

#### Gorm里面，有时候比如说我们的业务字段可能设的是0对吧？0在更新的时候更新不成功，你就有去了解过为什么0更新不成功吗？

因为 **GORM 会认为你没有赋值**，也就是会认为你没传这个字段。使用指针类型就可以解决这个问题，或者map方式更新。

#### update和save有什么区别？

updates 通常是部分字段更新；

save 是全量更新，也称**覆盖式更新**，如果是全新的对象则执行插入操作。

#### 如何使用Docker部署自己的项目？

略

#### 我们在Gin框架中，比如说我们对接的这个第三方服务，比如说这个服务返回的是抖音的一个作品的信息数据，这数据肯定非常大。然后我们去接收数据的时候呢，这个因为你的json非常大，可能有几兆。这个时候如果请求量很大的话，我们内存肯定就很快就被耗尽了，这个时候应该怎么办？

可以使用json的**流式解析**，也就是 json.Decoder，边读边处理。如果数据更大，还可以先进行落盘，比如落盘到一个缓冲文件，再进行流式解析。

#### 你项目里面有自己去包装中间件吗？讲一下？

我有用到 JWT Token 中间件来进行鉴权处理。Gin 的中间件本质上就是一个函数，签名为 `func(c *gin.Context)`，在请求进入路由前或者响应返回前执行。

```go
func AuthMiddleware() gin.HandlerFunc {
    return func(c *gin.Context) {
        token := c.GetHeader("Authorization")
        if !validateToken(token) {
            c.AbortWithStatusJSON(401, gin.H{"error": "unauthorized"})
            return
        }
        c.Next()
    }
}
```

### 9.3-幂律科技

做了面试题，无下文。

### 9.3-成都智云视界

#### 讲一下验证码的生成和校验过程？

验证码是被存储到redis里面的。

#### 你的验证码服务只是定义了一个生成验证码字符串的功能，用一个微服务来定义，不觉得设计得很重吗？

是的，在这里验证码服务只是单纯生成一个随机字符串，确实显得有些重。

但是拆出来不仅仅是因为“生成字符串”。验证码往往是注册、登录、敏感操作的**前置校验**，考虑到后续很多服务会依赖它。单独拆分，可以复用。未来可能增加图形验证码、语音验证码、多渠道下发（短信、邮件、App push），**提前拆分有利于后续的扩展。**

#### 讲一下你项目里的负载均衡策略？为什么选择加权轮询？

我的项目里面用到了加权轮循。**主要是考虑到服务器节点的性能有差异。**

1. **节点性能差异**：服务器配置不一致，或者某些实例和数据库更近，性能更好。
2. **资源利用最大化**：加权轮询能让强节点多承担，弱节点少承担，整体吞吐量更高。
3. **简单可靠**：加权轮询实现简单，维护成本低，适合大多数场景。

#### 你的项目里面有用到Prometheus监控系统的性能和指标，具体是怎么做的？

使用一个单独的goroutine来监控服务。

1、**定义监控指标：**计数器、仪表盘、直方图、摘要等；

2、在业务代码中**更新指标**：例如 **进入请求时 +1**、错误请求累加等；

3、**暴露 `/metrics` 接口**：`http.Handle("/metrics", promhttp.Handler())`，用于提供指标数据；

4、**配置抓取目标：**即在 Prometheus Server 中配置 `prometheus.yml`文件，告诉 Prometheus **从哪里抓取监控指标数据。**

5、数据存储与查询：Prometheus 会把采集到的时序数据存储在本地 TSDB（时间序列数据库）里。

6、Grafana 可视化：将 Prometheus 数据源接入 Grafana；

7、Alertmanager 告警：配置告警规则。

#### 我想知道你的Token设置的过期时间是多少，或者说怎么考虑去指定这个过期时间？以及怎么存储的？如何进行刷新？

1、这里采用JWT生成Token，包括两个token：**短期 Access Token + 长期 Refresh Token** 的机制。 Access Token 设置 2 小时过期，Refresh Token 设置 7 天；

**考虑因素**：

- **安全性**：时间越短，安全性越高，短期Token不宜超过2小时。
- **用户体验**：过短会导致频繁刷新 Access Token

由于是个人项目，所以使用了2小时过期机制，方便项目进行测试；

2、Token 存储在客户端，在项目中是存储在浏览器 LocalStorage 里面；

3、刷新机制采用上面的双 Token 模型：

- Access Token 过期后，客户端用 Refresh Token 请求新的 Access Token。
- Refresh Token 一旦过期或被撤销，必须重新登录。

#### IM实时通信的消息存储是怎么做的？

- 先写入 **消息队列（Kafka）**（保证高并发和异步解耦）。
- 消息同时存到 **MongoDB**（作为持久化存储）。
- 使用 **Redis** 缓存一些**热数据**（例如在线用户、最近会话（重要）、未读数）。
- minio存储图像、头像等数据。

| 数据类型         | 存储工具  | 用途                      |
| ---------------- | --------- | ------------------------- |
| 消息（聊天记录） | MongoDB   | 历史消息、漫游            |
|                  | Redis     | 最近消息、未读数缓存      |
|                  | Kafka     | 异步转发、削峰            |
| 用户账号/资料    | MySQL     | 注册信息、好友关系        |
| 会话列表         | Redis     | 最近会话缓存（SortedSet） |
|                  | MongoDB   | 会话持久化                |
| 未读数/已读回执  | Redis     | 实时计数                  |
|                  | MongoDB   | 持久化记录                |
| 文件/图片/语音   | OSS/MinIO | 存储大对象，DB 存 URL     |
| 在线状态         | Redis     | 在线/离线状态、连接信息   |
| 系统配置/权限    | MySQL     | 后台配置、角色权限        |

#### 讲一下golang的并发模型？

略

#### GC机制？

略

#### go语言中内存溢出、内存泄漏、内存逃逸的区别？

**1、内存溢出**

 系统已经不能再分配出你所需要的空间，比如系统现在只有1G的空间，但是你偏偏要2个G空间，这就叫内存溢出

**2、内存泄漏：  (Memory Leak)**

强引用所指向的对象不会被回收，可能导致内存泄漏，虚拟机宁愿抛出OOM也不会去回收他指向的对象

意思就是你用资源的时候为他开辟了一段空间，当你用完时忘记释放资源了，这时内存还被占用着，一次没关系，但是内存泄漏次数多了就会导致内存溢出

**3、内存逃逸：**

在一段程序中，每一个函数都会有自己的内存区域存放自己的局部变量、返回地址等，这些内存会由编译器在栈中进行分配，每一个函数都会分配一个栈桢，在函数运行结束后进行销毁，但是有些变量我们想在函数运行结束后仍然使用它，那么就需要把这个变量在堆上分配，这种**从"栈"上逃逸到"堆"上的现象就成为内存逃逸。**

#### go语言中如何避免内存泄露？

**1、goroutine泄漏**

这是最常见的内存泄漏场景之一。当goroutine无法正常退出时，其占用的内存资源就无法释放。

```go
// 典型的goroutine泄漏示例
func leakyGoroutine() {
    ch := make(chan int)
    // goroutine将永远阻塞在这里
    go func() {
        val := <-ch  // 没有其他goroutine会向这个channel发送数据
        fmt.Println(val)
    }()
}
```

解决方案:

- 使用context、sync.Waitgroup()控制goroutine生命周期
- 确保channel有**配对的读写操作**
- 合理设置超时机制（比如time.After(5 * time.Second)）

**2、切片/数组持续扩容**

当切片在追加元素时可能发生扩容,如果没有合理**控制容量**,很容易导致内存占用过大。

```go
// 可能导致内存问题的切片操作
func processLargeData() {
    data := make([]int, 0)
    for i := 0; i < 1000000; i++ {
        // 频繁扩容
        data = append(data, i)
    }
    // 使用完未及时清理
}
```

优化建议:

- **预估容量**提前分配（记住这个就好）
- 及时释放不需要的数据
- 考虑使用**内存池**（sync.Pool{}）

**3、定时器Timer/Ticker未释放**

```go
// 错误的timer使用方式
func startTimer() {
    ticker := time.NewTicker(time.Second)
    go func() {
        for {
            <-ticker.C
            // 处理定时任务
        }
    }()
    // ticker未被Stop
}
```

最佳实践:

- 使用完**及时调用Stop()**
- 配合context管理生命周期（case <-ctx.Done()）
- 避免在循环中创建timer

**4、全局变量/单例对象**

全局变量如果持续增长且没有清理机制,将导致内存持续增长。

```go
var globalCache = make(map[string][]byte)

func addToCache(key string, data []byte) {
    globalCache[key] = data  // 持续增长没有清理机制
}
```

解决方案:

- 使用带过期机制的缓存

- **设置容量上限**

- 实现LRU淘汰策略（自定义）

  ```go
  // 使用第三方库或自己实现LRU缓存
  import "github.com/hashicorp/golang-lru/v2"
  
  var (
      cache, _ = lru.New[string, []byte](1000)  // 设置最大容量
  )
  
  func addToCacheProperly(key string, data []byte) {
      cache.Add(key, data)  // 当超过容量时自动淘汰最久未使用的条目
  }
  ```

**5、defer使用不当**

在循环中使用defer可能导致资源无法及时释放。

```go
// 错误的defer使用方式
func processFiles(files []string) {
    for _, file := range files {
        f, _ := os.Open(file)
        defer f.Close()  // 直到函数返回才会释放
        // 处理文件
    }
}
```

正确做法:

- 将defer操作放在独立的函数中

  ```go
  // 正确做法：将文件处理逻辑封装到函数中
  func processFilesProperly(files []string) {
      for _, file := range files {
          processSingleFile(file)  // 每个文件单独处理
      }
  }
  
  // 每个文件的处理在独立函数中，defer会在函数结束时执行
  func processSingleFile(filename string) error {
      f, err := os.Open(filename)
      if err != nil {
          return err
      }
      defer f.Close()  // 这里的defer会在函数返回时立即执行
      
      // 处理文件...
      return nil
  }
  ```

- 及时关闭不需要的资源

- 使用sync.Pool复用对象

#### 切片和数组的区别？

略

#### 什么场景下适合用数组，什么场景下适合用切片？

**📌 适合用数组的场景：**

1. **长度固定、已知不变的数据**
   - 比如一周 7 天 `[7]string`，或 RGB `[3]uint8`。
2. **对性能有极致要求，避免额外内存分配**
   - 小的定长数据结构（比如矩阵、固定大小 buffer）。
3. **需要在编译期确定大小，作为常量定义的一部分**
   - 例如作为 map 的 key：`map[[16]byte]string`（切片不能作为 map key）。
4. **安全性要求高**
   - 数组传参是拷贝，避免了函数里对外部数据的意外修改。

------

**📌 适合用切片的场景：**

1. **数据长度不确定，需要动态扩容**
   - 常见的业务数据存储，用户列表、消息列表等。
2. **频繁做截取、追加、遍历等操作**
   - 切片支持 `append`、`s[i:j]` 等，灵活。
3. **需要高效共享底层数据，避免大规模复制**
   - 例如函数返回一段数据子集时，直接返回切片而不是复制数组。
4. **作为函数参数**
   - 切片更通用，几乎所有标准库 API 都用 `[]T`。
5. **和标准库/第三方库对接**
   - Go 生态里操作集合的 API 都是 `[]T`。

#### 在实际开发中，什么情况下会需要开启goroutine？

1、处理I/O 密集型操作：利用 goroutine 可以在等待 I/O 的同时去处理其他任务，提高程序吞吐量。

2、**定时任务**或周期性任务：这些任务通常是后台运行，不影响主业务流程。

3、**大任务分解成小任务并行计算**：把**大任务拆给多个 goroutine 并行执行**，利用多核 CPU 提升效率。

4、**处理一些异步任务**：不阻塞主流程，比如**日志记录**等

5、服务端的并发处理：例如并发处理每个连接 / 请求等；

#### 如何有效的控制多个Goroutine的运行，就是管理它的生命周期啊这些？

主要有sync.WaitGroup、Context、channel这几个；

**特别注意**：当关闭channel时， `<-done` 会立刻得到该类型的**零值**（比如 `struct{}{}`），并不是往channel里写了东西。

```go
func useChannel() {
    done := make(chan struct{}) // 用于传递退出信号的通道
    workerCount := 3

    // 启动工作 goroutine
    for i := 0; i < workerCount; i++ {
        go func(id int) {
            for {
                select {
                case <-done: // 收到退出信号
                    fmt.Printf("worker %d 退出\n", id)
                    return
                default:
                    fmt.Printf("worker %d 工作中\n", id)
                    time.Sleep(500 * time.Millisecond)
                }
            }
        }(i)
    }

    // 2秒后关闭通道，通知所有worker退出
    time.Sleep(2 * time.Second)
    close(done) // 关闭通道发送退出信号
    time.Sleep(time.Second)
    fmt.Println("所有worker已退出")
}
```

#### 怎么控制 goroutine 的数量？

使用官方协程池ants

#### 如何自己设计一个协程池？

定义一个pool结构体：一定要包含goroutine数量、用于装任务的有缓冲 channel

功能包括NewPool、启动 worker（start）、提交任务Submit、等待所有任务完成Wait、关闭池Close。

```go
// 定义任务类型
type Task func()

// 协程池结构
type Pool struct {
	workerCount int       // worker 数量
	tasks       chan Task // 任务队列
	wg          sync.WaitGroup
}

// 创建一个协程池
func NewPool(workerCount int, taskQueueSize int) *Pool {
	p := &Pool{
		workerCount: workerCount,
		tasks:       make(chan Task, taskQueueSize),
	}
	p.start()
	return p
}

// 启动 worker
func (p *Pool) start() {
	for i := 0; i < p.workerCount; i++ {
		go func(id int) {
			for task := range p.tasks { // 从队列取任务
				task()
				p.wg.Done()
			}
			fmt.Printf("worker %d 退出\n", id)
		}(i)
	}
}

// 提交任务
func (p *Pool) Submit(task Task) {
	p.wg.Add(1)
	p.tasks <- task
}

// 等待所有任务完成
func (p *Pool) Wait() {
	p.wg.Wait()
}

// 关闭池（不再接收新任务）
func (p *Pool) Close() {
	close(p.tasks)
}

func main() {
	pool := NewPool(3, 10) // 3 个 worker，任务队列容量 10

	for i := 0; i < 8; i++ {
		taskID := i
		pool.Submit(func() {
			fmt.Printf("任务 %d 开始执行\n", taskID)
			time.Sleep(1 * time.Second)
			fmt.Printf("任务 %d 执行完成\n", taskID)
		})
	}

	pool.Wait()  // 等待所有任务完成
	pool.Close() // 关闭池
}

```

“池子有结构 → worker 循环干活 → channel 投递任务 → WaitGroup 保证完成 → Close 优雅退出 → 扩展功能加分项”

#### 了解过单元测试吗？你一般什么场景下会想到要去写单元测试？

核心的业务逻辑：比如涉及订单生成、金额计算、权限验证等逻辑；

涉及边界条件：空值、最大/最小值、负数、异常输入。

#### 讲一下myisam和innodb引擎的区别？

核心区别对比表：

| 特性     | MyISAM                              | InnoDB                          |
| -------- | ----------------------------------- | ------------------------------- |
| 事务支持 | 不支持事务                          | 支持 ACID 事务                  |
| 锁机制   | 只支持表级锁                        | 支持行级锁 + 表级锁（默认行锁） |
| 外键约束 | 不支持                              | 支持                            |
| 崩溃恢复 | 不支持，**需手动修复**（myisamchk） | 支持，通过 redo log 自动恢复    |
| 存储结构 | 数据和索引存储在不同的文件          | 数据和索引存储在同一个文件      |
| 表的行数 | 保存有表的总行数                    | 没有保存表的总行数              |

#### MYSQL常见的索引有哪些？

**主键索引、唯一索引、普通索引、联合索引**、全文索引、前缀索引、空间索引等，前4个都属于B+树索引。一个表最多只有一个聚簇索引。

#### 现在生产环境上有一个SQL查询比较慢，你怎么样优化一下这个SQL，排查一些问题，你具体会怎样进行操作？

**1、确认慢SQL**：通过慢查询日志或者监控工具定位具体慢 SQL，并拿到**执行时间和返回行数。**

**2、执行计划分析**

重点关注 EXPLAIN 输出中的这些列：

- **type**：访问类型（ALL、index、range、ref、eq_ref、const/system）
  - ALL 表示全表扫描，通常需要优化
- **key**：实际使用的索引（NULL 表示未使用索引）
- **rows**：预估扫描行数（越小越好）
- **Extra**：额外信息（Using filesort、Using temporary 是性能杀手）

**3、检查表结构和索引使用情况：**确认 WHERE、JOIN、ORDER BY 涉及的字段是否有合适的索引，如果没有就加索引。是否符合最左前缀原则等；

**4、尝试优化 SQL 写法：**

- 避免在索引列上使用函数或计算
- 减少 `SELECT *`，只查需要的字段
- 拆分复杂 JOIN，考虑分步查询
- 避免子查询嵌套过深

**5、验证优化结果：**对比优化前后的执行计划（`EXPLAIN`）

#### 假如说索引已经解决不了问题了，你会考虑怎么做？

暂时没有很好的答案。

> 比如说你这个表的数据现在上千万级了，你索引加上去可能没什么用。你会考虑怎么优化？

- 考虑从业务层面重审 SQL 本身，只取必要字段，减少 I/O。

- **分表 / 分区**？

- **读写分离**：读请求走从库，主库只负责写。

#### 聊一下商城项目里面的分布式事务？

我使用了分布式事务的SAGA 模式，Saga 会把一个大事务拆分成一系列本地事务，每个本地事务都有对应的 **补偿操作**。

比如：

- **T1：创建订单**（补偿：取消订单）
- **T2：扣减库存**（补偿：加回库存）
- **T3：扣减余额**（补偿：退款）

如果执行链条中某一步失败，Saga 会按照**相反顺序调用补偿操作**，实现回滚效果。

> 在 **Saga 模式** 里，补偿逻辑就是 **从当前失败点，按相反顺序一路回退到事务开始点（初始点）**。

#### 我现在要处理系统的数据同步问题，如果不用分布式事务，你还有其他解决方式吗？

> 比如刚刚那个商品下单的例子，假如说不让你用分布式事务来做，你怎么来保证整个操作的原性？

还可以使用**发件箱模式**，也就是 Outbox Pattern。

**场景**

用户下单，系统要：

1. 在数据库里生成订单记录；
2. 同时需要通知库存服务去扣减库存。

如果直接在事务里调用 MQ 发送消息，一旦 MQ 发送失败，可能出现 **订单生成了，但库存没扣减** → 数据不一致。
 所以引入 **发件箱模式**。

**1、数据库设计**

- **订单表**：保存订单数据。
- **发件箱表 (outbox)**：保存要发送的消息。

例子：

```go
orders(id, user_id, amount, status, created_at)
outbox(id, event_type, payload, status, created_at)
```

**2、订单创建时（事务内）**

- 在 **同一个事务** 里：
  1. 插入一条**订单数据**（status=CREATED）。
  2. 往 **outbox** 表插入一条消息（event_type=OrderCreated，payload 包含 orderId 等信息，status=pending）。
- 一旦事务提交，订单和消息保证同时成功写入。

**3、发件箱消息投递器（后台任务）**

- 定时从 outbox 表里查询 **status=pending** 的消息；
- **发送到消息队列**（比如 Kafka/RabbitMQ）；
- 如果发送成功 → 更新该消息的 status=sent；
- 如果失败 → 重试几次，失败次数过多可以标记为 failed 进死信。

**4、消费者（库存服务）**

- 监听 MQ，收到 `OrderCreated` 事件；
- 扣减库存；
- 为了避免重复消费，库存服务要做 **幂等处理**（例如用 messageId 去重）。
- **消费失败时可以选择更改订单表的状态（如果需要）**

**5、清理**

- 已经成功投递的 outbox 消息可以定期删除或归档。

#### Docker容器和镜像有什么区别？

镜像是**容器的模板**，容器是镜像的**运行实例**。

| 名称 | 概念                                                         |
| ---- | ------------------------------------------------------------ |
| 镜像 | 镜像是 **静态的模板**，包含运行容器所需的文件系统、代码、依赖和配置。它是不可变的，只能被用来创建容器。 |
| 容器 | 容器是 **镜像的一个运行实例**，是动态的、可读写的，并且运行在隔离的环境中。容器可以启动、停止、修改，并生成自己的数据和状态。 |

#### 我现在要看一个容器的实时日志，命令怎么敲？

我会使用`docker logs -f <容器名>` 来**实时查看**容器日志。`-f` 表示持续输出日志，新日志会实时显示。

#### 最近在学习什么东西？有什么收获吗？

略

#### 快排的时间复杂度是多少？

nlogn

#### 反问

### 9.3-映宇宙（映客）

#### 为什么选择consul作为服务注册中心？

1、consul有自动的服务注册与发现机制，服务启动时可以自动注册，客户端调用时可以直接查询服务地址。

> Consul 提供了 **RESTful HTTP API**，客户端可以通过接口获取服务实例列表。

2、支持**健康检查**，自动剔除不稳定的节点。

> 例如：Consul 定期向服务暴露的 HTTP endpoint 发送请求。根据返回状态码判断服务健康状态。

3、对于微服务架构，Consul 可以让服务调用者通过**名称调用服务**而不是固定 IP，减少运维复杂度。

#### A是一个上游服务，B是下游服务，A要调用B，如果B服务有多个副本，如果某个副本有变化或者掉线，上游服务A理应知道这个变化。你是怎么处理的？

这个问题实际上考察的是 **微服务架构下的服务发现与动态感知机制**。

**目标**：A 能够实时感知 B 的实例变化（新增、下线、故障），避免调用不可用的节点。

**处理方案：**通过服务注册中心 + 健康检查（推荐）

Consul 支持**长轮询** (long-polling)、gRPC streaming。

**长轮询：**然后你本地管理一下你的服务名和IP的映射就行了。

```go
// 上游服务初始化 Consul 客户端
client, _ := api.NewClient(api.DefaultConfig())
health := client.Health()

// "B"：服务名，true：只返回健康的实例
services, meta, _ := health.Service("B", "", true, nil)
fmt.Println("当前可用实例：", services)


options := &api.QueryOptions{
    WaitIndex: meta.LastIndex, // 使用上次返回的索引
}

for {
    services, meta, _ := health.Service("B", "", true, options)
    fmt.Println("服务变化，更新实例列表：", services)

    // 更新 WaitIndex，等待下一次变化
    options.WaitIndex = meta.LastIndex
}
```

#### 讲一下覆盖索引？

#### 使用联合索引有什么注意事项？

1、将查询需求频繁或者**字段选择性高**的列放在前面。

2、需要按照建立索引时的字段顺序依次使用，否则无法命中索引。

3、尽量达到索引覆盖的要求。

#### MySQL的隔离级别有几种？

略

#### 可重复读能解决幻读问题吗？

能，但是有条件。

#### 项目里面有用过redis集群吗？

有的

#### redis的集群用到了什么分布式协议？

gossip协议：用于 **节点间状态传播**。

可以认为选举的过程使用了简化版的raft。

#### redis的集群在做迁移的时候可能会发生什么问题？

这个问题有点大

**扩容：**

1、**迁移超时：**拆分大 key、优化网络环境。

2、**数据不一致：**从备份恢复数据；使用lua脚本、锁或者事务来保证原子性。

3、**客户端连接异常**：更新客户端配置，确保客户端使用最新的集群节点信息。

#### redis的集群在做伸缩的时候，get一个key，这个key正好在做迁移，会有什么问题？

（1）key 还在源节点 → 正常返回；

（2）key 已经迁到目标节点 → 源节点返回 ASK 重定向，客户端需要临时请求目标节点；

Redis 提供了两种 **重定向机制**：

- **MOVED**：槽已经完全迁移 → 客户端要到目标节点取数据（不是本题考点）
- **ASK**：槽正在迁移 → 客户端临时去目标节点取数据。

#### 讲一下https整体的握手过程？

https的握手分为TCP握手+TLS握手。

**1、TCP 三次握手**

- 客户端 → 服务端：发送 `SYN`
- 服务端 → 客户端：回复 `SYN+ACK`
- 客户端 → 服务端：发送 `ACK`
   此时，TCP 连接建立完成（**注意不需要等待。**），双方可以进行可靠的字节流传输。****

4. 简化总结版（面试时可直接说）

**2、TLS握手**

1. 客户端发起请求，带上**第一随机数**和支持的**加密套件**；

2. 服务器响应，返回**第二随机数**和**数字证书；**

3. 客户**端验证证书**后，生成**预主密钥**，用服务器公钥加密传过去；

4. 双方使用**约定的算法**生成**会话密钥**；

后续数据传输就用对称加密（会话密钥）进行安全通信。

**问题1：**约定的加密算法是在哪里约定的？

> 在客户端发起 TLS 握手时，**加密套件里面。**

**问题2：**客户端如何验证TLS证书的合法性？

> **前提：**
>
> - 证书由受信任的 **CA（证书颁发机构）** 签发。
> - 客户端预先存储了一组受信任根 CA 的公钥。
>
> 好的，我们把你描述的 **CA 签发证书和客户端验证证书的过程**，从原理上详细拆解一下，让每一步都清晰、逻辑连贯。
>
> ------
>
> **1️⃣ CA 签发证书的过程（数字证书生成）**
>
> 假设我们有一个服务端 A，要申请证书：
>
> **步骤 1：准备信息**
>
> - 服务端 A 生成一对密钥：**私钥** 和 **公钥**（key1）。
> - A 向 CA 提交 **证书签名请求（CSR, Certificate Signing Request）**，里面包含：公钥（key1）、用途、颁发者、有效时间、还有一些其他额外信息；
> - 这些信息可以被 CA 打包成 **tbsCertificate（待签名证书内容）**。
>
> **步骤 2：Hash 计算**
>
> - CA 对打包好的证书信息使用**哈希算法**计算一个摘要值 H。（这个hash算法由CA机构指定，并包含在证书里）
>
> **步骤 3：CA 签名**
>
> - CA 使用自己的 **私钥** 对这个 Hash 值 H 进行加密，生成 **Certificate Signature**（数字签名）。
> - 因为只有 CA 掌握私钥，所以只有 CA 能生成这个有效签名。
>
> **步骤 4：生成数字证书**
>
> - 将 Certificate Signature 添加到证书文件中，并附上**原证书内容（tbsCertificate）。**
> - 最终的证书文件包含：tbsCertificate（原始证书内容）、SignatureAlgorithm（签名算法，也就是上面的hash算法）、Certificate Signature（签名值）
>
> 证书作完成后，机构将证书发给服务端A；
>
> ------
>
> **2️⃣ 客户端验证证书的过程**
>
> 当客户端 B 收到服务端 A 的证书时：
>
> **步骤 1：Hash 计算**
>
> - 客户端使用**和 CA 相同的哈希算法**（在SignatureAlgorithm字段中），对证书中 tbsCertificate 内容计算摘要值 H1。
>
> **步骤 2：使用 CA 公钥解密签名**
>
> - 客户端浏览器/操作系统中预装了 CA 的**公钥**（信任根）。
> - 客户端用 CA 公钥解密 Certificate Signature，得到 Hash 值 H2。
> - 这个解密过程就是验证签名：H2 是 CA 对证书内容生成签名的结果。
>
> **步骤 3：比较 Hash**
>
> - 如果 H1 == H2 → 说明证书内容在签发后未被篡改，并且确实由这个 CA 签发 → 证书可信。
> - 如果 H1 != H2 → 说明证书被篡改或不是这个 CA 签发 → 证书不可信。

#### 你一般怎么做golang的性能分析？

pprof、trace

#### 内存逃逸有了解吗？怎么避免内存逃逸？

✅ 如何减少/避免逃逸

1. **优先使用值类型传递**：能拷贝就不传指针。
2. **减少接口的使用**，避免不必要的装箱（在接口中存储值），因为需要运行时类型信息。
3. **切片、map预分配容量**，减少扩容带来的逃逸。
4. **复用对象**（如 sync.Pool），避免重复的堆分配。
5. **注意闭包的使用**，不要轻易把局部变量暴露到函数外部。
6. **合理使用结构体内嵌**，避免隐藏指针导致逃逸。

#### 我现在要查一下Linux服务器上一个4000的端口被哪个进程占用，该我怎么去查？

有netstat、ss、lsof 三个命令可以做到。

✅ **1. 常用命令查端口占用**

1、`netstat -tlnp | grep :4000`（较老，不推荐）

2、`ss -tlnp | grep :4000`**（推荐，现代 Linux 内置，高效）**

> **命令解析：**
>
> - `-t`：仅显示 TCP 端口（如果怀疑是 UDP，可加上 `-u`）
> - `-l`：仅显示监听（Listen）状态的端口（因为我们找的是服务进程）
> - `-n`：以数字形式显示端口和地址，不进行域名解析（加快速度）
> - `-p`：显示使用该端口的进程信息（**这是关键选项**）
> - `| grep :4000`：过滤出包含 `:4000` 的行

3、`lsof -i :4000`（备选方案，**功能强大**）

✅ **2. 查到 PID 后，可以进一步查看进程的详细信息。**

`ps -ef | grep 进程PID`

- **`-e`**：**显示所有进程**（every process）。不加这个参数，默认只显示当前终端启动的进程。
- **`-f`**：**显示完整格式**（full-format）。这会提供更详细的信息列。

#### 怎么去查某一个进程，它占用了哪些多少内存，多少CPU？

**1、top 命令：**

```bash
top -p <PID>
```

输出示例：

```bash
  PID USER  PR  NI VIRT   RES   SHR S %CPU %MEM TIME+  COMMAND
 1234 root  20   0 500M  200M  10M S  25.0  5.0  0:30.12 myapp
```

- `%CPU` → 占用 CPU 百分比
- `%MEM` → 占用内存百分比
- `RES` → 实际占用物理内存
- `VIRT` → 虚拟内存总量

**2、ps 命令：**

```bash
ps -p <PID> -o pid,ppid,cmd,%cpu,%mem,vsz,rss
```

输出示例：

```bash
  PID  PPID CMD      %CPU %MEM    VSZ   RSS
 1234     1 myapp    25.0  5.0 512000 204800
```

**3、htop**（交互式，比 top 更直观）：

1. 先在「终端」输入`htop`命令启动。
2. **按下 `F3` 键** 或者 **按 `/` 键**，然后输入 PID 搜索，就能看到 CPU 各核使用率、内存条形图。

#### 怎么去查询服务器上的磁盘的使用空间？

牢记df、du命令。

✅ **1. 查询整体磁盘使用情况**
 最常用：

```bash
df -h
```

输出示例：

```bash
Filesystem      Size  Used Avail Use% Mounted on
/dev/sda1        50G   30G   18G  63% /
tmpfs           2.0G  100M  1.9G   5% /run
/dev/sdb1       200G  150G   50G  75% /data
```

- `Size` → 总大小
- `Used` → 已用空间
- `Avail` → 可用空间
- `Use%` → 使用率
- `Mounted on` → 挂载点

------

✅ **2. 查询某个目录的占用空间**

*du* 命令用于查看**文件和目录**的磁盘使用情况

```bash
du -sh /var/log
```

输出：

```bash
1.5G  /var/log
```

#### 讲一下redis的滑动窗口限流？

广义的滑动窗口计数法的思路是：

1. 将一个**时间窗口**（是固定大小的）划分为细粒度的区间，**每个区间维持一个计数器**，每进入一个请求则将计数器加一。
2. 多个区间组成一个时间窗口，每流逝一个区间时间后，则抛弃最老的一个区间，纳入新区间。
3. 若当前窗口的区间**计数器总和**超过设定的限制数量，则本窗口内的后续请求都被丢弃。

但是redis中有一定区别，请看下一个问题。

#### redis中如何设计一个滑动窗口限流？

注意：在 **Redis 中实现滑动窗口限流** 时，**通常不需要人为拆分成多个小区间**。

实现方式：使用**ZSet + Lua脚本**实现。

假设规则：**某用户在 60 秒内最多允许 100 次请求**

```lua
-- 参数说明：
-- KEYS[1]: 限流的 Redis 键（有序集合）
-- ARGV[1]: 窗口大小
-- ARGV[2]: 限制的最大请求次数

local key = KEYS[1]
local now = tonumber(ARGV[1])
local window = tonumber(ARGV[2])
local limit = tonumber(ARGV[3])

-- 删除过期数据
redis.call("ZREMRANGEBYSCORE", key, 0, now - window)

-- 添加当前请求
redis.call("ZADD", key, now, tostring(now))

-- 设置过期时间，2倍窗口
redis.call("EXPIRE", key, window * 2 / 1000)

-- 统计请求数量
local count = redis.call("ZCARD", key)

if count > limit then
    return 0  -- 超过限流
else
    return 1  -- 放行
end
```

#### 快排的时间复杂度？

快速排序的性能高度依赖于选择的基准值。

如果每次能将数组分成两个大小大致相等的子数组，那么快速排序的效率最高。在这种情况下，排序过程可以看作是一个**平衡二叉树**，其中每个节点的操作时间为**O(n)**，树的高度为**O(log n)**。因此，整个排序过程的时间复杂度为**O(n log n)**。

在最差情况下，如果每次选择的基准值都是最小或最大的元素，那么数组将不会被平均分割，导致递归深度为**O(n)**，每层的操作时间仍为**O(n)**，因此总的时间复杂度为**O(n^2)**。

| 情况     | 时间复杂度 | 空间复杂度 | 发生条件                                   |
| :------- | :--------- | :--------- | :----------------------------------------- |
| 最佳情况 | O(n log n) | O(log n)   | 每次都能将数组分成两个大小大致相等的子数组 |
| 平均情况 | O(n log n) | O(log n)   | 分区划分随机                               |
| 最坏情况 | O(n²)      | O(n)       | 每次选择的基准值都是最小或最大的元素       |

#### 反问：Golang在哪些领域有优势？

中间件

### 9.5-湖南锐意马达

#### 题目1

> 现在有两台设备a和设备b，设备a上有一个按钮，按钮每按一下设备a就会向设备b发送一个包含设备名称、时间戳、激活状态的一个信息。设备b接收到信息会将信息存入数据库，怎么保证设备a每次按钮触发都正确的存入数据库，而且存入的信息不重复，注意要考虑到两次按按钮的时间很短的情况。

考虑时间戳自增或者加一个随机数：`设备名 + 时间戳 + 随机数/自增序列`。

#### 现在有2亿条这种格式的数据，如何设计一个存储方式或者压缩算法，减少这些数据在数据库中占用的空间？

**1、设备名压缩（前缀分组 / 字典编码）**

- 建立一个 **设备表**（字典），每个设备名映射成一个整数 ID。
   比如 `"DeviceA"` → `1`，`"DeviceB"` → `2`。
- 数据库中只存设备 ID，而不是完整设备名。
   👉 节省大量字符串存储空间。

**2、时间戳压缩（差分存储 / 时间序列化）**

- 因为时间戳是递增的，不需要每次都存完整时间戳。

- 可以存 **与上一次的差值（delta encoding）**。

  - 例如：

    ```sql
    2025-10-05 12:00:00  → 存完整
    +2s → 存 2
    +1s → 存 1
    +3s → 存 3
    ```

- 差分值通常比较小，可以用 **变长编码（如 VarInt）** 或者 **Run-Length Encoding (RLE)** 进一步压缩。

**3、激活状态压缩（有限空间编码）**

- 激活状态如果只是 `0/1` 或有限枚举，可以直接存为 **1 bit / 2 bit**。
- 甚至可以按时间序列把一段时间的状态打包成 **bitset** 批量存储。

### 9.23-一零跃动

#### 简单讲一下MySQL的锁？

MySQL的锁按照粒度划划分可以分为全局锁、表级锁、行级锁。平时主要用的是行级锁，比如行级锁里面的共享锁、排他锁。

#### 讲一下MySQL的回表？

当MySQL使用非覆盖索引查询时，需要先通过（二级）索引找到主键，然后再根据主键找到完整的行数据。

#### 讲一下B树和B+树的区别？

B树的非叶子节点也存储数据。

#### 解决过慢查询吗？

先查看有没有开启慢查询日志，它记录了执行时间长的 SQL 语句的相关信息。

然后通过执行计划来分析：查看索引使用情况、Type字段、扫描行、是否使用联合索引等；

分析执行计划后再根据具体情况来优化SQL语句。

#### 讲一下联合索引失效的情况？

**1. 不满足最左匹配原则** 联合索引遵循最左匹配原则，即查询条件必须包含索引的最左列。如果查询条件中缺少最左列，索引将失效。例如，索引 *(name, age, msg)* 中，*WHERE age = 20* 不会使用索引，而 *WHERE name = 'Andy' AND age = 20* 则可以正常使用。

**2.使用了select ***，在联合索引下，尽量使用明确的查询列来趋向于走覆盖索引；

**3. 索引列使用了函数或运算** 如果查询条件对索引列进行了函数处理或运算，索引将失效。例如，*WHERE SUBSTR(name, 1, 3) = 'And'* 或 *WHERE age + 1 = 20* 都会导致全表扫描。

**4. 错误的like使用** 在 *LIKE* 查询中，如果条件以 *%* 开头，索引将失效。例如，*WHERE name LIKE '%Andy'* 会触发全表扫描，而 *WHERE name LIKE 'Andy%'* 则可以使用索引。

**5. 类型隐式转换** 查询条件的参数类型与字段类型不一致时，MySQL 会进行隐式转换，导致索引失效。例如，*WHERE age = '20'*（age 为 INT 类型）可能触发全表扫描。

**6. OR条件** 当查询条件中包含 OR 且其中一个字段未建立索引时，整个查询会导致索引失效。例如，*WHERE name = 'Andy' OR age = 20* 会触发全表扫描。

**7.不等于比较**使用不等于操作符时，索引可能失效，尤其是当结果集占比较大时。例如，*WHERE age != 20* 通常会导致全表扫描。

**8. IS NOT NULL** 对于 *IS NOT NULL* 的查询，索引通常不会生效，而 *IS NULL* 则可以正常使用索引。

**9.not in和not exists**，查询条件使用not in/not exists时，如果是主键则走索引，如果是普通索引，则索引失效。

**10. order by导致索引失效** 在 *ORDER BY* 或 *LIMIT* 查询中，如果排序字段未满足最左匹配原则或**涉及多个字段**，索引可能失效。

**11. 查询结果集过大** 当查询结果集占全表数据的比例较高（通常超过 10%-30%），MySQL 优化器可能会**选择全表扫描**而非使用索引。

#### 联合索引的顺序是(a,b,c)，查询条件是`WHERE b = ? AND a = ? AND c > ?`，这时候会用到联合索引吗？

可以用到，而且可以**完整使用整个联合索引。**

------

**附加：**如果查询条件是 `WHERE b > ? AND a = ? AND c > ?`，那么只可以部分用到联合索引

- **a** → 精确匹配
- **b** → 范围扫描
- **c** → 索引失效

#### 为什么在大字符串上建索引不好，或者你知道在大字符串上建索引会有什么问题吗？

1. 建索引时，索引列的值会被完整的存储在索引页中；
2. MySQL的页的默认大小是16KB，所以**大字符串会占用更多的页空间**。如果有几百万条大字符串，索引占用空间就非常大；
3. 索引文件大，必然导致缓存命中率下降，查询时就可能触发大量的磁盘 I/O；

总结：在大字符串建索引，空间消耗巨大，可能频繁触发磁盘I/O。

#### Redis有哪些使用场景？

**缓存热点数据**、计数器、排行榜、限流、**消息队列**、消息发布订阅、会话管理（Token存储等）、**分布式锁**、地理位置服务等；

#### Redis的分布式锁怎么实现的？一般用于什么场景？

Redis 实现分布式锁是一种常见的技术，主要利用 Redis 的原子操作和高性能特性来确保多个客户端在分布式环境中对共享资源的互斥访问。以下是实现分布式锁的核心步骤和关键点：

**1、基本实现方式**

**核心命令：**SET key value NX PX timeout

**2、关键问题与解决方案**

**(1) 锁的自动过期**

- 设置过期时间（如 `PX timeout`）可以避免因客户端崩溃或网络异常导致的死锁。
- 但需要注意，锁的持有时间应大于业务逻辑的执行时间，否则可能出现锁提前过期的问题。

**(2) 锁的安全释放**

- 使用 Lua 脚本保证释放锁的原子性：
  - 检查锁的值是否匹配（确保是当前客户端持有的锁）。
  - 如果匹配，则删除锁。
- Lua 脚本在 Redis 中是原子执行的，避免了并发问题。

**(3) 高可用性**

- 单节点 Redis 存在单点故障风险，可以使用 Redlock算法，在多个 Redis 节点上实现分布式锁的高可用性。

**3、Redlock 算法**

Redlock 是由 Redis 作者提出的一种分布式锁算法，适用于多 Redis 节点的场景。其核心思想是：

1. 在多个 Redis 节点上尝试加锁
2. 加锁成功节点数 ≥ N/2+1 时认为锁获取成功
3. 加锁失败则释放已加锁节点

适合在多节点 Redis 环境下保证分布式锁的安全性

2️⃣ 使用场景：**秒杀 / 抢购**

- 控制库存扣减的唯一性
- 防止超卖

#### 讲一下MySQL的主从复制？

MySQL 主从复制就是大体分 3 步：

1. **主库**：把数据变更（写操作）记录到 **binlog（二进制日志）**。
2. **从库**：I/O 线程连接主库，拉取 **binlog**，写入到本地 **relay log（中继日志）**。
3. **从库**：SQL 线程**读取 relay log**，执行 SQL，完成数据同步。

👉 总结：**主写 binlog → 从拉 relay log → 从执行 SQL 完成数据同步**

#### 如何保证接口的幂等性？同样的请求参数过来，保证服务端只处理一次。

**1、全局唯一号**

- 客户端生成唯一请求号（比如 `orderId`、`requestId`）
- 服务端根据这个 Key 判断是否已处理过

比如通过source来源 + 唯一序列号传入给后端，后端来判断请求是否重复，在并发时只能处理一个请求，其他相同并发请求要么返回请求重复，要么等待前面请求执行完成后再执行。

**2、加唯一索引**

数据库加唯一索引，比如 `INSERT INTO orders(order_id, ...) UNIQUE`，重复插入会失败。

**3、防重令牌**

- 客户端在调用接口前，先从服务端申请一个唯一 Token
- 每次请求必须带上 Token，服务端校验并消费（删除）
- 同一个 Token 只能用一次

**4、分布式锁**

- 请求时对业务关键字段加锁（比如用户ID、订单号）
- 同一时刻只能有一个请求处理，其他请求要么等待要么直接失败

#### 讲一下linux系统里面的Cron？

这个问题考察的是对 **Linux 定时任务（Cron）** 的理解，回答时要讲清楚：**它是什么、怎么用、应用场景**。

------

1️⃣ Cron 是什么

- **Cron** 是 Linux 系统里的一个**定时任务调度工具**，常驻在后台运行。
- 它会按照配置文件（**crontab**）里设定的规则，周期性执行任务。

------

2️⃣ Cron 的配置文件

- 每个用户都可以有自己的 **crontab** 配置（保存在 `/var/spool/cron/`），系统也有全局配置 `/etc/crontab`。

- 查看 / 编辑命令：

  ```bash
  crontab -l   # 查看当前用户的定时任务
  crontab -e   # 编辑定时任务
  ```

------

3️⃣ Cron 表达式格式

Cron 表达式由 **5个时间字段 + 命令** 组成：

```shell
* * * * *  	command
分 时 日 月 周  命令
```

含义：

- `分`（0–59）
- `时`（0–23）
- `日`（1–31）
- `月`（1–12）
- `周`（0–7，0和7都表示星期日）

特殊符号：

- `*` → 任意值
- `,` → 多个值
- `-` → 范围
- `/` → 步长

------

4️⃣ 示例

```bash
# 每天凌晨 2 点执行备份脚本
0 2 * * * /home/user/backup.sh

# 每 5 分钟执行一次任务
*/5 * * * * /home/user/task.sh

# 每周一上午 8 点执行
0 8 * * 1 /home/user/report.sh
```

------

5️⃣ Cron 的应用场景

- **日志清理**：每天凌晨清理过期日志
- **数据备份**：定时备份数据库、文件
- **定时脚本**：执行 ETL、生成报表
- **运维监控**：定时检测服务状态、磁盘空间

------

6️⃣ 注意点

- Cron 的环境变量有限，不一定和用户 shell 一致，所以要写全路径（比如 `/usr/bin/python`）。
- 输出要么重定向到日志文件，否则默认会发邮件给用户。
- 如果任务依赖网络/外部服务，要注意容错。

------

**使用步骤举例：**

**1、明确需要定时执行的命令、脚本：**

比如准备一个数据库备份脚本 `backup_mysql.sh`。

**2、编写 Cron 任务：**

1. **打开 crontab 编辑界面**：执行命令 `crontab -e`（用户级任务），首次使用会提示选择编辑器（如 vim、nano），选择后进入编辑模式。

2. **添加任务配置**：

   示例：每天凌晨 3 点执行备份脚本，并将输出日志保存到文件：

   ```bash
   0 3 * * * /home/user/backup_mysql.sh >> /var/log/mysql_backup.log 2>&1
   ```

\💡 **面试口语版回答**：

Cron 是 Linux 系统的定时任务调度服务，它会根据 crontab 配置文件里的规则周期性执行任务。Cron 常见的应用场景包括**日志清理、数据库备份、报表生成和运维监控。**

#### 讲一下Go里面的Timer的结构？

Timer 的实现原理在runtime 层，Go 的定时器是由 runtime 管理的，内部用了一个 **小根堆** 来存储所有定时器（定时任务）：

1. **定时器存储**：

   - 每个 `Timer` 记录触发时间（when）、回调函数（f）、周期（period，用于 Ticker）等信息；
   - runtime 里用一个 **时间小根堆**（最早触发的 timer 在堆顶）来组织；
   - 回调函数可能是系统自己的：当时间到达时，向 `Timer.C` 发送当前时间。也有可能是用户的，但是需要经过内部包装。

2. **检查定时器堆**

   Go 的调度器有一个 **timerproc 协程**（每个 P 绑定一个，减少锁竞争），专门负责检查定时器堆。

   - **检查堆顶元素：**
     - 如果堆为空（没有定时任务），`timerproc` 会进入休眠状态，直到有新任务被添加时被唤醒。
     - 如果堆不为空，计算当前时间与最早到期任务的触发时间（`when`）的差值：
       - 若任务已到期（时间差 ≤ 0），直接执行任务。
       - 若任务未到期，`timerproc` 会休眠对应的时间差（通过系统调用实现），**避免空轮询消耗 CPU。**
   - 当到达最早任务的触发时间时，从堆中取出该任务并进入后续处理。
   - 重复上述过程，处理下一个到期任务。

3. **执行到期任务**：当到达触发时间时，timer 会从堆中移除该到期任务，然后执行回调函数 f。

   - 对于 `time.NewTimer` / `time.After`，回调会向 `Timer.C` 投递一个 time.Time 类型的时间戳；
   - 对于 `time.AfterFunc`，回调会执行用户传入的并经过内部包装的函数。

------

1、堆的每一个点就是一个 `runtime.timer` 结构体，注意这不是我们用户声明的Timer。它代表了一个“定时任务”。

2、runtime.timer的结构里有一个成员函数f：

```go
f  func(any, uintptr) // 触发时要执行的函数
```

**注意：**

- 对于 `time.NewTimer` / `time.After`：
   runtime 给 `f` 填的是一个系统函数，用来 **往 `Timer.C` channel 投递 `time.Time`**。
- 对于 `time.AfterFunc`：
   runtime 给 `f` 填的是一个包装函数，它会调用你传入的回调函数（比如 `func(){...}`），并由调度器启动一个 goroutine 来执行。

```go
// 1.单纯NewTimer
func NewTimer(d Duration) *Timer {
	c := make(chan Time, 1)
	t := (*Timer)(newTimer(when(d), 0, sendTime, c, syncTimer(c)))
	t.C = c
	return t
}

func sendTime(c any, seq uintptr, delta int64) {
	select {
	case c.(chan Time) <- Now().Add(Duration(-delta)):
	default:
	}
}

// 2.注意调用了NewTimer
func After(d Duration) <-chan Time {
	return NewTimer(d).C
}

// 3.调用了用户自己的func
func AfterFunc(d Duration, f func()) *Timer {
	return (*Timer)(newTimer(when(d), 0, goFunc, f, nil))
}

func goFunc(arg any, seq uintptr, delta int64) {
	go arg.(func())()
}
```

#### 讲一下map的底层实现？

map的底层实际上是一个哈希表，具体来说是一个hmap的结构体，这个结构体会指向一个桶数组，键值对都是存储在桶里面。

#### 怎么确定桶的大小？

hmap里面有一个B字段，表示桶的数量；

#### key的哈希值的高8位和低5位有什么作用？

**1、高8位**就是tophash，查询时可以快速判断 key 是否可能匹配。

- 若不匹配，直接跳过该位置的键，无需比较完整hash值；

- 若匹配，再进一步比较完整哈希值和key本身（避免哈希冲突）；

  注意这里先比较了完整哈希值再比较key本身；

**2、低 5 位**用于确定键在桶内的具体位置（即桶内索引）。

### 10.1-海亮教育科技

#### 自我介绍、离职原因、目前状态等？

略

#### 你之前有没有做过项目？

有的

#### 讲一下上家公司OA系统现有的一些功能？

**流程审批：**用得最多，包括人事、行政、采购、财务、合同、项目立项（包括IT）

**人事管理：**包括人事档案、招聘录用、考勤打卡、绩效考评、生日提醒等；

**行政管理：**会议室申请、接待安排等

**知识管理：**制度、公告等；

**合同管理：**集成了电子签章，契约锁等；

**费控管理：**费用报销、费用申请等，与金蝶系统进行集成；

**资产管理：**管理公司博物馆藏品、其他固定资产；

**档案管理：**与中信光典系统集成、归档一些重要的流程；

其他的个性化功能

#### 讲一下OA系统周边系统的对接？

企业微信、飞书（不确定）、infor ERP 系统、金蝶EAS、明基HR、电子签章（契约锁）、培训系统（云学堂）、明源云、京东采购（不确定）、WMS系统（被替换了？）、光典系统（做档案管理）等等；

#### 系统里面大概有多少条流程？大概都是哪些部门在用？

大概有100多条。使用的部门有人事、行政、IT、财务、营销等部门；

#### IT部门大概有哪些流程？

故障报修、设备更换、项目管理（立项、验收、开发需求、权限申请、IT类采购等）

#### 项目立项的这个流程里面有哪些环节，包括哪些字段？

**需求发起：**项目名称、需求部门、需求提出人、需求背景与目标、业务场景描述、期望交付时间

**可行性分析：**现有技术、预算等；

#### 写过项目立项树书吗？

没有

#### 你的日常实施运维工作都有哪些？

- 流程搭建、调整、优化、异常调整，报表展示
- 系统异常处理
- 系统权限管理
- 考勤模块对接
- 流程归档集成
- 接口对接说明
- 使用手册维护
- 个性化报表建模
- 使用培训、指导

- 二次开发：表单优化、调页面、SQL优化；
- 版本升级、异常账号监控等

#### 你的OA处理流程什么样的？比如说业务反映一个问题，他大概什么样的一个流程？

**需求接收：**业务一般通过emobile、电话等找到我，然后我们基本上要保证在十分钟之内给一个回复；

**问题排查：**与业务沟通，明确是个例问题还是范围性的问题，确认问题的紧急度；

**迅速做出解决方案：**提供尝试性地方案，远程查看等，确定问题深度，是否需要供应商协助等；

**跨部门协作：**是否需要找其他部门的人；

**记录问题：**方便下次排查，如果是系统问题，看一下是否需要及时调整；

#### 你做泛微OA实施运维工作已经三年了，从你工作的角度，你有没有发现你们公司有哪些工作环节或者流程需要优化，比如说有些地方做得不好，你有没有什么好的解决办法？

**1、流程审批链条过长，效率低**

如果有时因为人员变动未及时更新，流程就走不下去。

优化：增加自动跳过、使用岗位来审批等

**2、表单设计字段不统一（项目中）**

需要牵头各个部门统一表单字段

**3、用户培训、问题反馈机制做得不好**

很多OA使用问题其实不是系统bug，但是用户不了解功能，对接人也没有很好的宣导，所以直接反馈到运维人员这里，造成很多无效运维；

优化：根据用户地反馈地一些日常问题，及时更新用户使用手册，督促用户查看；

#### 你觉得在你之前的公司的工作中有哪些工作对你来讲是有挑战的，不好处理的？

**复杂流程表单设计**：尤其需要跨部门、跨公司，协作复杂度高，需要积极开会讨论；

**跨系统集成bug**：数据字段的映射要做好；多方协作，积极主动；

总的来说，**人力沟通成本**这一块是比较重要的，确定好了需求，实施起来会很快；

### 10.13-东莞立讯技术

#### 介绍一下在公司做的项目？

我在上一家公司做过一个完整的OA项目，这个项目是我所在的公司的控股公司的OA项目，然后我是全程参与的；

这个项目主要是为了解决集团各分子公司、各部门的流程混乱的问题，原先使用的金蝶的审批模块，比较分散；

整个系统的基础功能包括流程管理、人事考勤、费控、资产管理等等；其中流程管理占主要的部分；

我在整个项目中，我作为甲方公司的主要实施人员，相当于一个中间人的角色，一方面负责与集团各业务部门、各分子公司沟通需求；另一方面和泛微的项目组进行对接；

在项目推进过程中，我参与了从需求调研、方案设计、具体的实施、功能测试，到上线验收的整个过程。

整个项目历时大约一年半，最终顺利上线并通过集团验收；

上线后，我还负责OA系统的用户培训、使用指导和运维优化的工作；

#### 介绍一下整个过程里面你做了哪些事情？

作为中间人

#### OA你这个系统掌握了哪些技能可以介绍一下吗？

流程、权限、简单的二次开发（比如页面调整，接口对接）

#### 有没有做过跟周边系统集成的那一块？

有的，HR、金蝶、erp的一些数据

#### 有没有做过接口嵌合等？

提供接口规范

#### 互相聊一下工作情况

略

### 10.14-名匠网络

#### 一面：

#### 你在整个OA实施中的相关的一系列的像模块，然后这些工作是从需求到最终的实施交付测试等等系列，简单给我介绍一下，包括你们整个项目的人员配比。

整个系统的基础功能包括流程管理、人事考勤、费控、资产管理等等；其中流程管理占主要的部分，做好的功能会让业务部门也帮忙测；整个项目大概是一年的时间，验收是一年半。我们这边一共有4个实施人员，一个项目经理，3个实施人员。到后期在现场的就只有两个人了；

#### 你负责OA系统的日常运维、技术支持，这块主要做哪些工作？



#### 二面：

### 10.19-桂鑫钢铁

安全问题、交通、签证、住宿条件、伙食、园区的生活、购物这些、网络、想出去如何请假；
